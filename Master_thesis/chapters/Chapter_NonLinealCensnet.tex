 % \chapter{Enhanced Natural Gas Flow Predictions Using Physics-Guided Neural Networks} 
\chapter{Stochastic Modeling of Natural Gas Flows Using Physics-Guided Neural Networks} \label{cap:non_linealcensnet}

% While the GNN-based model from \cref{cap:lienal-censnet} was designed as a fast alternative to the optimization-based model, this chapter introduces physics-informed elements into the network architecture. Specifically, the model now includes loss terms based on the gas balance and Weymouth equations to ensure the predicted flows comply with the physical laws governing gas transportation. These constraints, integrated through additional layers in the model, guide the learning process, penalizing deviations from the gas balance equation (\cref{eq:gas_balance}) and the Weymouth equation (\cref{eq:weymouth_cons}). The modified model maintains the same structural components, such as input channels, convolutional layers, and loss functions for node and edge predictions, with the difference that the balance equation and the Weymouth equation are now considered loss functions. 
This chapter aims to explore the integration of physical knowledge and stochastic modeling into graph-based neural network architectures to improve natural gas flow predictions under uncertainty. Building upon previous deterministic configurations, the proposed approach introduces physical constraints, such as nodal balances and the Weymouth equation, directly into the model’s loss function to enhance prediction accuracy. Additionally, a stochastic framework is developed to quantify the uncertainty in both objective and decision variables related to gas system operations. Through a series of experiments, including applications to a simplified 8-node network and the Colombian national gas network, the chapter evaluates the trade-offs introduced by different loss function combinations. It demonstrates the model’s ability to generalize under stochastic sampling, thereby advancing the development of a physics-guided and uncertainty-aware gas dispatch optimization strategy.


\section{Methodology}

Physics-Informed Neural Networks (PINNs) represent a class of neural networks where physical laws are incorporated into the learning process, guiding the model to respect these constraints. Unlike traditional neural networks, where the loss function is typically based on the discrepancy between predicted and actual data, PINNs introduce additional terms in the loss function that penalize the model for deviating from known physical principles.

In this case, the physical constraints are derived from the gas balance and the Weymouth equations, which describe the flow and pressure behavior within the gas transportation network. These constraints are integrated into the neural network model introduced in \Cref{cap:lienal-censnet} as additional loss terms. Specifically, we define two layers within the network: one that calculates the error in gas balance and another that calculates the error in the Weymouth equation. The outputs of these layers are then used to adjust the network's predictions, ensuring that they adhere to the physical laws governing the system.

The inclusion of these physics-informed layers allows the network to achieve better generalization, as it is not only trained on the data but also guided by the underlying physical laws. This approach can be seen as a specialized form of regularization, where the model is penalized if its predictions do not satisfy the physical constraints. The overall loss function can be expressed as:

\begin{equation}
   \mathcal{J}(\Theta) = \mathcal{J}_{\text{data}}(\Theta) +  \mathcal{J}_{\text{balance}}(\Theta) +  \mathcal{J}_{\text{weymouth}}(\Theta),     
    \label{eq:PINN_basic_definition}
\end{equation}

\noindent with \( \mathcal{J}_{\text{data}}(\Theta) \) representing the traditional data-driven loss, \( \mathcal{J}_{\text{balance}}(\Theta) \) is the loss associated with the gas balance constraint, and \( \mathcal{J}_{\text{weymouth}}(\Theta) \) is the loss associated with the Weymouth equation constraint. 



The gas balance constraint is enforced at each node through the following loss function:

\begin{equation} \label{eq:gas_balance_GNN}
\mathcal{J}_{\text{balance}} =  \mathbf{T} \cdot \hat{\mathbf{f}}_e - \mathbf{d} + \hat{\mathbf{f}}_n .
\end{equation}

\noindent In here, \( \hat{\mathbf{f}}_e \in \mathbb{R}^{N_e} \) is the predicted edge flow, \( \hat{\mathbf{f}}_n \in \mathbb{R}^{N_v} \) is the predicted nodal injection, \( \mathbf{d} \in \mathbb{R}^{N_v} \) is the actual demand, and \( \mathbf{T} \in \mathbb{R}^{N_e \times N_v} \) is the signed incidence matrix.


The Weymouth constraint relates the gas flow to the difference of squared pressures between connected nodes through the following this loss function:

\begin{equation} \label{eq:Weymouth_GNN}
\mathcal{J}_{\text{weymouth}} =  \mathbf{M}_{\mathcal{P}} \left( \hat{\mathbf{f}}_e^{\circ 2} - \mathbf{K} \circ \left( \mathbf{T} \cdot \hat{\boldsymbol{\pi}}^{\circ 2} \right) \right),
\end{equation}


\noindent begin \( \hat{\boldsymbol{\pi}} \in \mathbb{R}^{N_v} \) the predicted pressure at each node, \( \hat{\mathbf{f}}_e^{\circ 2} \) is the element-wise square of edge flows, , the vector \( \mathbf{K} \in \mathbb{R}^{N_e} \) contains the Weymouth constants for each edge and is zero for compressors, while \( \mathbf{M}_{\mathcal{P}} \in \mathbb{R}^{N_e \times N_e} \) is a diagonal matrix that selects only the pipeline edges \( p \in \mathcal{P} \). Together, these physics-informed components guide the neural network toward solutions that not only fit the data but also obey the operational and physical laws of gas transport.


For practical implementation, we build upon the experimental setup outlined in \Cref{sec:LinealCensnet_ExperimentalSetup}, maintaining the same general approach while incorporating new elements that account for the physics of the natural gas system represented in \Cref{eq:gas_balance_GNN,eq:Weymouth_GNN} following the scheme shown in \Cref{fig:nonlineal_model_description}. The samples are generated using the nonlinear natural gas network optimization model from \Cref{cap:optimization_mpcc}. In this process, a power-interconnected system was considered; however, since this study focuses on the gas system, the power system remained constant without variation. As in the previous setup, noise was introduced into the base values of two gas networks: a small-scale test network of 8 nodes and the more extensive Colombian natural gas transportation system. The noise levels, ranging from 5\% to 25\%, simulate various operating conditions, providing diverse training data.


\begin{figure}[h]
    \centering
    \setlength\figurewidth{1\textwidth}        
    \setlength\figureheight{0.4\textwidth}
    \resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/model_description.tex}}
    % \input{figures/Chapter_LinealCensnet/MLP_def.tex}
    \caption{General outline of the CensNet-based model with physics guidance.}
        \label{fig:nonlineal_model_description}
\end{figure}

\section{Results}


In this section, we present the results of the proposed model, which now incorporates physical constraints from the natural gas system. The focus remains on the relationship between the predicted outputs and the actual observed values, evaluating the model's performance across the 8-node test network and the Colombian natural gas transportation system. By incorporating physics-based constraints, the goal is to assess the model's ability to predict critical parameters under various operational conditions while ensuring that the physical laws governing gas flow are respected.

\subsection{Case Study I: 8-node Network}



In this chapter, we begin with experiments that account for both node and edge losses, as it was found that considering only the node loss did not produce adequate results. The best parameters identified for this experiment were $N \ channels=25$, $N \ layers =4$, and $N \ dense = 11$. These settings yielded a total loss of 6.8, with a node loss of 2.8 and an edge loss of 4.02.

The results corresponding to the nodes, shown in \Cref{fig:results_nonlineal_dummy_base_node}, exhibit a similar behavior to that observed in 
\Cref{fig:results_dummy_node_base_f}, demonstrating that the model accurately captures the injection pattern at the nodes. The correlation between the actual and predicted values is also strong, as indicated by an $R^2$ of 0.983. In turn, edge flows show some variation, as seen in \cref{fig:results_nonlineal_dummy_base_f}, mainly when predicting the flows through the first pipeline connected to the injection field, where slight deviations from the actual flow values were observed in the blue dots. However, the model performed well overall, achieving an $R^2$ of 0.983 for the edge flows. While the first pipeline presents some prediction challenges, the accuracy in predicting flows across the remaining the pipelines remains high, demonstrating the model's ability to handle the complexity of gas transportation in this nonlinear system.


\begin{figure}[h] 
    \centering
    \setlength\figurewidth{.5\textwidth}        
    \setlength\figureheight{0.32\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_base_node}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}


The second part of this experiment involves the additional loss associated with the gas balance, building upon the previous setup that considered both node and edge losses. The hyperparameter optimization yielded the best parameters: $N \ channels =61$, $N \ layers =2$, and $N \ dense=2$. These settings resulted in a total loss of 10.041, with a node loss of 2.9, an edge loss of 6.4, and a balance loss of 0.78. The prediction behavior at the nodes, as shown in \Cref{fig:results_nonlineal_dummy_node_base_f_bal}, remained consistent with the results obtained in the previous experiment, where the balance loss was not included. The model accurately captured the gas injection pattern, with an $R^2$ of 0.983 for node flow predictions, identical to the earlier case. Similarly, the prediction of edge flows, shown in \Cref{fig:results_nonlineal_dummy_edge_base_f_bal}, followed the same general trend as before, although a slight decrease in accuracy was observed, reflected by an $R^2$ of 0.973. While this represents a minor reduction in performance compared to the previous experiment, the model still demonstrated a strong ability to predict gas flows through the edges, maintaining a high level of accuracy.

\begin{figure}[h]
    \centering
    \setlength\figurewidth{.5\textwidth}        
    \setlength\figureheight{0.32\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f_bal.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f_bal.tex}}}
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance loss in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}


In the following part of this experiment, we incorporated losses associated with node and edge flows, the gas balance, and the Weymouth equation. The hyperparameter optimization for this setup yielded the following best parameters: $N \ channels=17$, $N \ layers =1$, and $N \ dense =4$. These settings resulted in a total loss of 20.670, with the individual losses being a node loss of 3, an edge loss of 11.35, a balance loss of 2.72, and a Weymouth equation loss of 3.59. As shown in \Cref{fig:results_nonlineal_dummy_node_base_f_bal_wey}, the behavior of the node flow predictions remained consistent with the previous experiments, with an $R^2$ of 0.983. The model continued to accurately capture the gas injection patterns at the nodes. However, the prediction accuracy for edge flows showed a notable deterioration, as seen in \Cref{fig:results_nonlineal_dummy_edge_base_f_bal_wey}. The $R^2$ value for edge flow predictions dropped to 0.952. This decrease in performance is primarily due to the difficulties encountered in predicting flows along edges 1, 2, 6, and 7. Edges 1 and 2 correspond to pipelines that are part of a closed path in the network, while edges 6 and 7 correspond to compressors. These complexities in the network configuration likely contributed to the reduction in predictive accuracy for these specific edges.

\begin{figure}[h]
    \centering
    \setlength\figurewidth{.5\textwidth}        
    \setlength\figureheight{0.32\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_f_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f_bal_wey.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_f_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f_bal_wey.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance and Weymouth losses in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}

In the subsequent experiment, the losses associated with node flows and the physical equations—namely, the gas balance and the Weymouth equation—were considered. The hyperparameter optimization process resulted in the best parameters being $N \ channels=18$, $N \ layers=1$, and $N \ dense=5$. These settings led to a total loss of 10.270, with a node loss of 3.976, a balance loss of 4.75, and a Weymouth equation loss of 1.55. The prediction at the nodes, shown in \Cref{fig:results_nonlineal_dummy_node_base_bal_wey}, remained largely consistent with previous experiments, though there was a slight decrease in accuracy, with the $R^2$ value dropping to 0.976. This minor reduction indicates that the model continues to perform well in predicting gas injection patterns at the nodes. However, the prediction accuracy for edge flows, as seen in \cref{fig:results_nonlineal_dummy_edge_base_bal_wey}, experienced another decline. The $R^2$ value dropped to 0.899, reflecting increased difficulties in predicting flows through the compressors and the pipeline connected to the injection field. 



\begin{figure}[h]
    \centering
    \setlength\figurewidth{.5\textwidth}        
    \setlength\figureheight{0.32\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_bal_wey.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_bal_wey.tex}}}
    
    \caption{Model results using the loss associated with nodal flow predictions along with the gas balance and Weymouth losses in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}



% In the final stage of the experiment, only the losses associated with nodal flows and the Weymouth equation were considered. The optimal hyperparameters for this configuration were $ N \ channels=22$, $ N \ layers=1$, and $ N \ dense=19$. These parameters yielded a total loss of 2.798, entirely attributed to the node loss, while the Weymouth loss was effectively zero.
%
% The node predictions, as depicted in \cref{fig:results_nonlineal_dummy_node_base_wey}, continued to perform similarly to most of the previous tests, with an $R^2$ of 0.983, indicating consistent and accurate predictions of gas injection patterns at the nodes.
%
% However, the edge predictions, shown in \cref{fig:results_nonlineal_dummy_edge_base_wey}, were significantly off target in this case. The model struggled to generalize edge flows, resulting in a drastically negative $R^2$ of -2.32, signaling a complete failure in predicting gas flows through the network's edges. 
%
% \begin{figure}
%     \centering
%     \setlength\figurewidth{.53\textwidth}        
%     \setlength\figureheight{0.36\textwidth} 
%     \subfloat[Actual vs predicted nodal flows.] 
%     {\label{fig:results_nonlineal_dummy_node_base_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_wey.tex}}}
%     \subfloat[Actual vs predicted edge flows.] 
%     {\label{fig:results_nonlineal_dummy_edge_base_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_wey.tex}}}
%     
%     \caption{Model results using only the loss associated with nodal flow predictions in the 8-node network.}
%     \label{fig:dummy_base_results}
% \end{figure}
%
%



% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
%     \hline
%     Method & \centering N & \centering E & \centering B & \centering W & Node Value & Edge Value & Balance Value & Time \\ \hline
%     IPOPT  &  &  &  &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} &  &  &  & 4.81 ± 12.64 & 0.42 ± 2.36 & -0.016 ± 17.448 & 0.13 ± 0.03 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  &  & 4.92 ± 13.02 & 22.96 ± 15.36 & 0.095 ± 1.678 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & 4.83 ± 12.65 & 23.20 ± 14.92 & 0.004 ± 0.845 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & 4.76 ± 12.51 & 22.93 ± 14.64 & -0.070 ± 1.665 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & \makebox[0.55cm]{\centering \checkmark} & 4.88 ± 12.01 & 20.58 ± 12.99 & 0.046 ± 2.187 & 0.13 ± 0.03 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} &  &  & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} &  &  & \makebox[0.55cm]{\centering \checkmark} & 4.91 ± 12.81 & -0.091 ± 0.185 & 0.079 ± 17.225 & 0.14 ± 0.05 \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, nodal balance, and prediction time between IPOPT and GNN across different loss configurations. The columns "N", "E", "B", and "W" indicate experiments where nodal, edge, balance, and Weymouth losses were considered.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}
%


% \begin{table}[htbp]
% \centering
% \begin{tabular}{|l|c|c|c|c|}
%     \hline
%     Method & Node Error & Edge Error & Balance Error & Time \\ \hline
%     CensNet (N) & 0 ± 17.99 & 22.76 ± 15.43 & -0.01 ± 17.45 & 0.86 ± 0.53 \\ \hline
%     CensNet (N+E) & -0.11 ± 18.265 & 0.22 ± 21.645 & -0.119 ± 1.706 & 0.85 ± 0.532 \\ \hline
%     CensNet (N+E+B) & -0.02 ± 18.003 & -0.02 ± 21.335 & -0.028 ± 0.899 & 0.85 ± 0.532 \\ \hline
%     CensNet (N+E+W) & -0.07 ± 17.560 & 2.60 ± 20.033 & -0.070 ± 2.209 & 0.86 ± 0.531 \\ \hline
%     CensNet (N+E+B+W) & 0.05 ± 17.905 & 0.25 ± 21.140 & 0.046 ± 1.693 & 0.85 ± 0.532 \\ \hline
% \end{tabular}


\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
    \hline
    Method & Node Error & Edge Error & Balance Error & Time \\ \hline
    CensNet(N) & 0 ± 17.99 & 22.76 ± 15.43 & -0.01 ± 17.45 & 0.86 ± 0.5 \\ \hline
    CensNet(N+E) & -0.11 ± 18.27 & 0.22 ± 21.65 & -0.12 ± 1.7 & 0.85 ± 0.5 \\ \hline
    CensNet(N+E+B) & -0.02 ± 18 & -0.02 ± 21.3 & -0.03 ± 0.9 & 0.85 ± 0.5 \\ \hline
    CensNet(N+E+W) & -0.07 ± 17.56 & 2.6 ± 20.03 & -0.070 ± 2.21 & 0.86 ± 0.5 \\ \hline
    CensNet(N+E+B+W) & 0.05 ± 17.91 & 0.25 ± 21.14 & 0.05 ± 1.69 & 0.85 ± 0.5 \\ \hline
\end{tabular}
\caption{Comparison of the differences in mean and standard deviation values for nodal flows (Node Error), edge flows (Edge Error), nodal balance (Balance Error), and prediction time (Time) between the optimization-based benchmark (IPOPT) and the CensNet-based models. Each value reflects the difference between IPOPT and the respective model.}
\label{tab:base_nl_dummy_results_simplified}
\end{table}

The results in \Cref{tab:base_nl_dummy_results_simplified} present the differences between the IPOPT benchmark and the CensNet-based models trained with different combinations of loss functions. The model trained with only the nodal loss (CensNet (N)) achieves nearly identical nodal flow predictions compared to the benchmark, but shows a large discrepancy in edge flow values. This confirms that training without edge-level supervision leads to significant errors in edge behavior, despite accurate nodal outputs.

When the edge loss is added (CensNet (N+E)), the model achieves a substantial reduction in edge flow error, improving from 22.76 to 0.22. This improvement is accompanied by a decrease in balance error, suggesting that learning edge-level patterns enhances global consistency across the network. Adding the balance loss (CensNet (N+E+B)) leads to further improvements in balance prediction, reducing the error to just -0.028 with small changes in nodal and edge differences, confirming that this constraint contributes to overall physical consistency.

The inclusion of the Weymouth loss (CensNet (N+E+W)) increases the edge flow error slightly and leads to a modest rise in balance error. However, the nodal prediction remains accurate, showing that incorporating physical knowledge through the Weymouth constraint introduces trade-offs without severely degrading model accuracy. Finally, combining all losses (CensNet (N+E+B+W)) yields a balanced model with low errors across all metrics and maintains high consistency with the benchmark.

All CensNet-based models significantly outperform the IPOPT method in terms of inference time, offering over an order of magnitude faster predictions with minimal variability. Among the tested configurations, \textbf{CensNet (N+E+B)} achieves the best overall performance, with the smallest errors in edge flow and balance, while preserving nodal accuracy and computational efficiency.

% \begin{table}[htbp]
% \centering
% \begin{tabular}{|l|c|c|c|c|}
%     \hline
%     Method & Node Value & Edge Value & Balance Value & Time \\ \hline
%     IPOPT & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     CensNet (N) & 4.81 ± 12.64 & 0.42 ± 2.36 & -0.016 ± 17.448 & 0.13 ± 0.03 \\ \hline
%     CensNet (N+E) & 4.92 ± 13.02 & 22.96 ± 15.36 & 0.095 ± 1.678 & 0.14 ± 0.05 \\ \hline
%     CensNet (N+E+B) & 4.83 ± 12.65 & 23.20 ± 14.92 & 0.004 ± 0.845 & 0.14 ± 0.05 \\ \hline
%     CensNet (N+E+B+W) & 4.76 ± 12.51 & 22.93 ± 14.64 & -0.070 ± 1.665 & 0.14 ± 0.05 \\ \hline
%     CensNet (N+E+W) & 4.88 ± 12.01 & 20.58 ± 12.99 & 0.046 ± 2.187 & 0.13 ± 0.03 \\ \hline
% \end{tabular}
% \caption{Comparison of the mean and standard deviation values for nodal flows (Node Value), edge flows (Edge Value), nodal balance (Balance Value), and prediction time (Time) between the optimization-based method (IPOPT) and the CensNet-based models under different loss configurations. The notation \textbf{CensNet (N)} indicates that only the nodal loss was considered during training, while \textbf{CensNet (N+E)}, \textbf{CensNet (N+E+B)}, and so on indicate combinations of nodal (N), edge (E), balance (B), and Weymouth (W) losses.}
% \label{tab:base_nl_dummy_results_simplified}
% \end{table}
%  
%
%
% The results in \Cref{tab:base_nl_dummy_results_simplified} compare the performance of the traditional IPOPT optimizer and the CensNet-based model trained with different combinations of loss functions. The evaluation focuses on nodal and edge flow prediction accuracy, network balance, and computation time. As a baseline, the IPOPT optimizer yields consistent results across all evaluated metrics, offering a reference for model performance. In contrast, the CensNet-based approaches reveal how incorporating physical constraints progressively improves the model's predictive accuracy. When trained with only the nodal loss, the CensNet matches the optimizer's performance in predicting nodal flows while maintaining nodal balance, despite poorly performing in edge flow estimation. This result reflects the absence of edge- and balance-specific information during training, which is essential for reproducing physically consistent flows in the network.
%
% Adding edge loss to the training objective enhances the GNN’s ability to predict edge flows, bringing them in line with the optimizer’s outputs. This improvement comes with reduced variability in the nodal balance, indicating that learning edge-specific relationships also reinforces overall network consistency. The introduction of the balance loss further stabilizes the model’s performance. With this additional constraint, the GNN reduces balance error variability and further aligns both nodal and edge flow predictions with the benchmark.
%
% Finally, incorporating the Weymouth equation into the loss function introduces the non-linear physics of gas transport into the learning process. Although this results in a modest reduction in balance accuracy compared to the previous configuration, it still maintains high predictive performance for nodal and edge flows. Notably, despite the increasing complexity introduced by each added constraint, all GNN models maintain a low and consistent prediction time—markedly faster than the optimization-based method—demonstrating the GNN’s scalability and computational efficiency.


% \subsubsection{Stochastic Analysis}

A stochastic analysis was conducted to assess the robustness of the trained CensNet-based model and its ability to generalize under uncertainty. This analysis evaluates the model’s consistency and robustness within the distribution of the training data, particularly in generating outputs from synthetic input samples, thereby quantifying its reliability within this learned space. Initially, a kernel density estimate (KDE) was fitted to the input training data used for the CensNet model. From this estimated distribution, a set of synthetic input samples, denoted as \( X_{\text{sample}} \), was generated. These synthetic inputs were then propagated forward through the trained network, taking into account all loss components, to yield a corresponding set of output predictions, denoted as \( y_{\text{sample}} \). In parallel, the original training inputs were propagated through the network to obtain output predictions, denoted as \(\bar{y}_{\text{train}}\). A second KDE was then fitted using the training output data (hereafter referred to as \(y_{\text{train}}\)). Two log-likelihoods were calculated based on this second KDE: one using \(y_{\text{sample}}\) and the other using \(\bar{y}_{\text{train}}\). The log-likelihood for the synthetic outputs, \(y_{\text{sample}}\), was found to be \(-6,696,247.56\), while the log-likelihood for the training outputs, \(\bar{y}_{\text{train}}\), was \(-6,657,534.62\). The closeness of these two values suggests that the synthetic outputs generated from the input KDE closely resemble the distribution of the training outputs.

To evaluate the goodness-of-fit between the distributions of \( y_{\text{sample}} \) and \( \bar{y}_{\text{train}} \), a Kolmogorov–Smirnov (K–S) test was conducted using three alternatives: two-sided, less, and more significant. The test results were as follows: a two-sided test yielded a statistic of \( 0.01833 \) with a p-value of \( 0.81482 \) (statistic location \(-0.34018\); the 'less' alternative produced a statistic of \( 0.01167 \) with a p-value of \( 0.72137 \) (statistic location \(0.30738\); and the 'greater' alternative returned a statistic of \( 0.01833 \) with a p-value of \( 0.44640 \) (statistic location \(-0.34018\). These statistical measures provide an indication that the synthetic outputs generated via the KDE-based sampling are consistent with the distribution of outputs observed during training, demonstrating the model's ability to maintain consistency under uncertainty within the learned data distribution. After completing the stochastic analysis of the variables associated with the optimization model, the next step involves leveraging the KDE fitted to the training data. This fitted KDE was used to generate a new set of input samples that represent the learned probability distribution of the optimization model's inputs. These samples were then forward-propagated through the trained neural network model. 

Following this analysis, we next study the uncertainty inherent in the network by approximating the joint probability density functions (PDFs) for the input variables. For training, each node was assigned five inputs, corresponding to the lower limit of gas injection capacity, the upper limit of gas injection capacity, the demanded flow, the lower limit of pressure, and the upper limit of pressure. Since the lower limits are permanently fixed at zero, these two variables were excluded from the analysis. Although the training data were initially sampled from a uniform distribution, only the successfully converged samples during the optimization process were retained. Consequently, the resulting PDFs do not exhibit a uniform distribution; instead, they display a variety of distribution shapes.


\Cref{fig:joint_distributions_input_input} presents the first group of joint distributions identified in this study, characterized by the presence of two distinct modes, which likely correspond to the two main operating regimes of the system. This group includes joint patterns involving the injection node ($N_0$), the demand nodes ($N_6$ and $N_7$), and several intermediate or pass-through nodes ($N_2$, $N_4$, and $N_5$). The observed relationships reflect the physical and topological structure of the network, particularly the connections among injection, compression, and demand points. A relationship is observed between the upper-pressure limits at nodes \( N_2 \) and \( N_4 \), which aligns with their placement within a sequential compression segment of the network. Node \( N_2 \) serves as the output of the first compressor and the input to the second, while node \( N_4 \) lies on a closed-loop path downstream of this compression chain. The correlation between their pressure bounds likely reflects how the viable operating range at one point in the compression sequence affects neighboring nodes within the loop. Similarly, the pressure limit correlation between node \( N_5 \), also part of the closed path, and the downstream demand node \( N_6 \), suggests that feasible pressure ranges propagate along connected elements of the network, especially where compression and demand interact. A subgroup of distributions reveals strong associations between the maximum demand at node $N_7$ ($\overline{f_u}$) and upstream variables. Specifically, $N_7$'s maximum flow shows dependence on the maximum injection flow at node $N_0$ ($\overline{f_w}$), and on the maximum pressures at nodes $N0$, $N1$ (compressor 1 input), and $N5$. These patterns suggest that the flow capacity at the far end of the system ($N_7$) is conditioned by both supply and compression states at the upstream nodes. Also, a direct relationship is identified between the pressure limits of node $N_7$ and node $N_4$. Given their physical connection, this correlation likely reflects the way pressure constraints propagate between adjacent sections of the network.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs.png}
    \end{center}
    \caption{Bimodal joint PDFs identified in the training inputs of the 8-node gas network. }\label{fig:joint_distributions_input_input}
\end{figure}

Using the network results obtained from the KDE fit, a new joint analysis was conducted, analogous to the previous one performed with the variables of the optimization model. Following the same structure presented in the first part of this analysis, we begin by highlighting the relationships that exhibit two distinct modes of operation according to their joint probability density functions. In this case, as shown in Figure~\cref{fig:joint_distributions_input_input_KDE}, only two variable pairs present this bimodal behavior when the analysis is performed using the inputs propagated through the trained neural network. These pairs are: the nodal pressure limits of $N_4$ and $N_2$, and those of $N_6$ and $N_5$. In both cases, the joint PDFs suggest the existence of two operational regimes, potentially associated with alternative configurations or routing strategies within the network that are learned by the neural model. 


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs (Sampled).png}
    \end{center}
    \caption{Bimodal joint PDFs from the KDE-sampled input data propagated through the CensNet model for the 8-node network.}
    \label{fig:joint_distributions_input_input_KDE}
\end{figure}
 


\Cref{fig:joint_distributions_input_input_no_mode} presents a second group of joint distributions identified in the study, which are characterized by low probability concentrations at their extreme values and generally diffuse patterns with small high-probability regions. This behavior, visually represented by lighter tones across most of the joint probability density functions and occasional darker spots, suggests a weaker or more dispersed correlation structure between the involved variables. Several of these relationships involve the injection node $N_0$ and its connection to both upstream and downstream nodes in terms of maximum pressure ($\overline{\pi}$) and maximum injection flow ($\overline{f_w}$). For instance, the joint distributions between the maximum pressure at $N_2$ and $N_0$, as well as between the maximum pressures at $N_3$, $N_4$, and $N_6$ with that of $N_0$, reveal broadly scattered patterns with localized high-probability points. This indicates that while these variables are structurally related, their extreme values do not consistently co-occur. A similar pattern is observed in the distributions involving the maximum pressure at $N_3$ and the injection capacity at $N_0$. Despite the proximity of these nodes within the system’s trajectory, the weak concentration suggests a more flexible operational regime or buffering effect along the path. Further examples include the relationships between $N_5$ and both $N_0$ and $N_2$, where again, the lack of sharp and extensive density at the extremes hints at variability in how pressure is maintained or transmitted through these nodes. Lastly, the distributions between the maximum pressure at $N_6$ and both $N_0$ and $N_3$ continue this trend, reinforcing the understanding that, in these cases, the system does not exhibit a strong link in the upper operational ranges of the involved variables.


\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.8\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_no_mode.png}
    \end{center}
    \caption{Joint PDFs between the inputs used in the 8-node network with a high probability zone concentrated in a small region.}
    \label{fig:joint_distributions_input_input_no_mode}
\end{figure}

Continuing with the distributions that exhibit a small high-probability region (\Cref{fig:joint_distributions_input_input_no_mode_KDE}), three pairs of variables were identified in this case whose joint PDFs display this characteristic. These pairs are: The Upper injection limit and the nodal pressure limits between $N_0$ and $N_1$; the pressure limits between $N_1$ and $N_4$; and the gas flow demand in $N_6$ and the nodal pressure limit in $N_4$. These distributions are characterized by a concentrated and sharply defined region of high probability, suggesting that the neural network tends to favor very specific combinations of input values during prediction. 

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.75\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_no_mode (KDE).png}
    \end{center}
    \caption{Joint PDFs between the inputs used in the 8-node network with a high probability zone concentrated in a small region in the KDE sampled variables.}
    \label{fig:joint_distributions_input_input_no_mode_KDE}
\end{figure}



\Cref{fig:joint_distributions_input_input_wide_mode} presents a third group of joint distributions distinguished by the presence of large dark zones in the joint probability density functions, indicating regions of high probability concentration. These distributions suggest strong dependencies between the involved variables. A clear example is the distribution involving the maximum injection flow at node $N_0$ and the maximum pressure at node $N_1$, which corresponds to the input of the first compressor. The high-probability region observed here suggests a consistent relationship between the capacity to inject gas into the network and the pressure conditions at the compressor’s intake, possibly reflecting operational constraints or control strategies that maintain a stable relationship between these variables. Likewise, the joint distribution between the maximum pressure at node $N_1$ and the pressure at node $N_4$ (a pass-through node connected downstream) also shows a dense concentration of probability. This implies a strong coupling between the input conditions of the first compressor and the downstream pressure, likely due to the system’s physical configuration and flow continuity. Lastly, a similar pattern is observed in the joint distribution between the maximum demand at node $N_6$ and the pressure at node $N_4$. The high-probability zone here may indicate a regulatory relationship, where variations in demand at $N_6$ are closely associated with pressure conditions at $N_4$, possibly due to their direct physical connection and the influence of demand on local pressure levels. It is worth noting that, unlike in this case, no distributions with large, clearly defined areas of high probability (i.e., darker and more extensive areas) were observed in the joint PDFs obtained from the adjusted KDE.


\begin{figure}[htbp]
    \centering
    \includegraphics[width=.8\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_wide_mode.png}
    \caption{Joint PDFs between the inputs used in the 8-node network, which have a considerably wide mode with respect to the entire distribution.}
    \label{fig:joint_distributions_input_input_wide_mode}
\end{figure}


 
To continue with the stochastic analysis, here we discuss the joint probability density functions (PDFs) that exhibit noteworthy behaviors, obtained from the output variables of the optimization model when it was supplied with the various scenarios generated through the previously described sampling process. It is important to note that, at this stage, each output variable was normalized with respect to the maximum capacity used in the corresponding scenario. That is, the values of the variables shown in this section are expressed relative to the maximum value that the variable could reach under that specific configuration.


\Cref{fig:joint_distributions_output_output_2} displays a set of joint probability density functions in which the flow through pipeline $p_3$, the component that closes the loop in the network, takes on negative values across all scenarios. These values typically fall within 10\% to 30\% of the normalized maximum, and are consistently observed along the X-axis of each subplot. The Y-axis in these figures corresponds to various system outputs, including normalized gas injection flow from the injection field, nodal pressures, and flows through other pipelines in the network. The observed negative values can be attributed to the assumed direction of flow in the optimization model, which turned out to be opposite to the one required for optimal operation. The model resolves this discrepancy by assigning negative values to the flow in $p_3$. Although this pipeline is not necessary for system operability, it plays a role in cost minimization, which explains its limited but consistent utilization.


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.75\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_2.png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network, which have a negative flow.}
    \label{fig:joint_distributions_output_output_2}
\end{figure}


\Cref{fig:joint_distributions_output_output_2_KDE} presents a second set of joint PDFs based on KDE-sampled data, which reinforces the patterns discussed previously. Again, the flow through pipeline $p_3$ (X-axis) consistently takes on negative values, indicating a reversal in the direction assumed during model formulation. This trend reflects the network’s ability to adapt under optimal conditions and highlights the model’s alignment with physical and economic system constraints. The robustness of this behavior is supported by a range of Y-axis variables, including the total injection at node $N_0$ and the flows through pipelines $p_0$, $p_1$, $p_2$, $p_4$, and $p_5$, which show relationships with the reversed flow in $p_3$.



\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.8\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_2 (KDE).png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network, which have a negative flow in the KDE sampled variables.}
    \label{fig:joint_distributions_output_output_2_KDE}
\end{figure}
 


\Cref{fig:joint_distributions_output_output_1} presents the joint distributions that exhibit a bivariate gamma distribution-like shape. In this case, the X-axis corresponds to the normalized flow transported through pipeline $p_1$, which connects nodes $N_3$ and $N_4$ and forms part of the system’s closed-loop trajectory. The Y-axis in each of the four subplots represents the normalized nodal pressure at nodes $N_3$, $N_4$, $N_6$, and $N_7$, respectively. Nodes $N_3$ and $N_4$ are part of a compact subsystem of pass-through nodes that define the core loop of the network. $N_6$ and $N_7$, while functioning as demand nodes, are connected downstream of this region, with $N_7$ specifically being supplied via node $N_4$. This spatial arrangement suggests that the observed distributions highlight the interdependence between the transported flow through this central pipeline and the pressure conditions at nearby or downstream nodes. In particular, although $N_6$ is slightly more distant, its role as a demand node may explain its inclusion in this group of correlated behaviors.


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.75\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_1.png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network have a behavior quite similar to that of a bivariate gamma distribution.}
    \label{fig:joint_distributions_output_output_1}
\end{figure}







\Cref{fig:joint_distributions_output_output_3} displays a third group of joint probability density functions that exhibit another pattern. In these distributions, both variables tend to take values within a range—approximately between 25\% and 70\% of their respective maximum capacities. Despite this wide span, the distributions do not resemble uniform patterns. Instead, they appear to exhibit a clear concentration of higher probability in a more restricted interval, specifically when both variables fall between 30\% and 40\% of their normalized limits. This behavior is particularly evident in the joint PDFs that relate nodal pressures across different yet structurally connected regions of the system. One set of these distributions involves the pressure at the injection node ($N_0$) and the pressures observed at downstream nodes, including the compressor-connected nodes ($N_1$, $N_2$, and $N_3$), as well as the nodes forming the closed loop ($N_3$, $N_4$, and $N_5$) and the final demand nodes ($N_6$ and $N_7$). These distributions suggest a degree of coordination in the pressure values that extends from the injection point through the compression stages and into the rest of the system. The tendency of these variables to cluster within a narrower operational range may indicate that the system's feasible configurations favor pressure levels that are not too close to the lower or upper bounds, but rather stabilized in a middle region that ensures both efficiency and reliability. This is especially relevant in subsystems like the closed-loop segment formed by nodes $N_3$, $N_4$, and $N_5$, which play a critical role in redistributing flow toward the demand points. The same applies to the pressures at the terminal load nodes ($N_6$ and $N_7$), which depend on adequate upstream conditions to meet demand.


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_3.png}
    \end{center}
    \caption{Joint probability density functions (PDFs) between nodal pressure outputs in the 8-node network, highlighting a concentration of values within mid-range operating levels (30\%–40\% of normalized limits)}
    \label{fig:joint_distributions_output_output_3}
\end{figure}
 


% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_linear.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which have a quite marked linear behavior.}\label{fig:joint_distributions_output_output_linear}
% \end{figure}
%  
%
% Figure~\ref{fig:joint_distributions_output_output_linear} illustrates a group of joint distributions exhibiting a markedly linear behavior, almost as straight lines with a clear slope. These distributions capture the relationships between the pressures at a given node and those at downstream nodes, starting with node N4, which is positioned at the outlet of the compressors. This linear trend is expected because, in order to maintain unidirectional gas flow, the pressures throughout the network must decrease gradually. 
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_5.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which have a Gaussian behavior with small covariances }\label{fig:joint_distributions_output_output_5}
% \end{figure}
%  
%
% Another group of joint distributions, which can be seen in Figure~\cref{fig:joint_distributions_output_output_5}, was observed to resemble a normal distribution closely but with much lower dispersion, indicating smaller covariances among the variables. These distributions were obtained by correlating the flow through the first pipeline with the pressures measured at all nodes in the network. Similar patterns are also observed when the nodal pressures are compared with the flows through edges E6 and E7; however, these images are omitted because the three edges are connected sequentially and share the same gas flow, their behavior is as expected.
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_6.png}
%     \end{center}
%     \caption{Joint PDFs among the outputs used in the 8-node network, which are quite dispersed along the variable associated with the N7 node flow.}\label{fig:joint_distributions_output_output_6}
% \end{figure}
%  
%
% Figure~\cref{fig:joint_distributions_output_output_6} shows the group characterized by distributions that are elongated along the axis of the first variable used in constructing the joint PDF while exhibiting a narrower spread along the second variable's axis. In our study, this subgroup includes the distributions that relate the gas flow on edge E4—which carries gas to the N7 demand node—to the pressures measured at each node. This behavior suggests that variations in the gas flow on E4 are more strongly influenced by the pressure variable, resulting in a pronounced elongation in that direction. 
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_7.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which show a negative linear behavior. }\label{fig:joint_distributions_output_output_7}
% \end{figure}
%  
%
% A final group of joint distributions can be seen in Figure~\cref{fig:joint_distributions_output_output_7}. This group is characterized by distributions with an inversely proportional behavior. The joint PDFs in this group are associated with the relationship between the flow transported by edge E3 and the flows transported by the other edges, except those corresponding to edges E4 and E5. This result is interesting, as it reflects a distinct behavior of the system: edges E1, E2, and E3 form a closed trajectory, and according to the initially assumed flow direction, there were instances in which edge E3 exhibited a flow opposite to that expected. In contrast, the flows that do not display this inverse relationship leave the closed trajectory to feed the demand nodes.
%
%
% The relationships between input and output variables were further analyzed to conclude the study of the joint distributions obtained from the variables in this case study. As in previous analyses, several groups of distributions with similar behavior were visually identified. 
%
%

It is also relevant to examine the joint probability distributions between input and output variables (\Cref{fig:joint_distributions_inputs_outputs_1}), particularly those in which the input variables exhibit significantly broader dispersion compared to the outputs. This behavior can be observed in a group of joint PDFs where the outputs—specifically, the flow through pipeline $p_4$—tend to remain concentrated within the 20\% to 40\% range of their normalized capacities, while the corresponding input variables vary much more widely. It is important to highlight that, in this case, normalization was only applied to the output variables. The inputs, being defined as upper bounds or operational limits (such as the maximum allowable injection flow or pressure limits), were not normalized. The most illustrative examples of this pattern involve joint distributions between the upper bound of the injection flow at node $N_0$ and the flow in $p_4$, as well as between the upper nodal pressure bounds at nodes $N_0$ through $N_7$ and the same pipeline output. Pipeline $p_4$ corresponds to the final segment delivering gas to one of the system’s demand nodes. The limited range of variation in this output, despite the broad dispersion in input conditions, suggests that the optimizer consistently resolves the system by prioritizing stable and relatively low utilization of this pipeline. 


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.9\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_1.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a wide dispersion along second variable. }
    \label{fig:joint_distributions_inputs_outputs_1}
\end{figure}

As shown in \Cref{fig:joint_distributions_inputs_outputs_1_KDE}, there is a group of joint probability distributions where the input variables span a wide range of values, while the corresponding output,specifically, the flow through pipeline $p_4$, remains narrowly concentrated between 20\% and 40\% of its normalized capacity. This behavior mirrors what was previously discussed, suggesting that, even under the learned data distribution, the network consistently predicts a relatively low and stable utilization of this particular pipeline. The pairs exhibiting this characteristic include the upper bound on injection flow at node $N_0$ and the upper bounds on nodal pressures at nodes $N_0$ through $N_7$, all compared against the predicted flow through pipeline $p_4$. As in the previous case, normalization was only applied to the output variables, while the inputs were left in their original scale. The similarity in joint distribution patterns between the optimization model and the neural network predictions indicates that the trained model effectively internalized a similar resolution strategy, favoring stable usage of pipeline $p_4$ regardless of the variability in input conditions.


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.9\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_1 KDE.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a wide dispersion along second variable. }
    \label{fig:joint_distributions_inputs_outputs_1_KDE}
\end{figure}


Another remarkable group of joint PDFs arises from the relationship between input and output variables that exhibit a seemingly linear behavior, shows in \Cref{fig:joint_distributions_inputs_outputs_2}. In these distributions, an increase in the input variable tends to be associated with an increase in the output variable, suggesting a positive correlation. This pattern is especially evident in the pairs formed by the upper bound of the demand flow at nodes $N_6$ and $N_7$, and the flow transported through pipelines $p_4$, $p_5$, $p_6$, and $p_7$. These pipelines are directly or indirectly responsible for supplying gas to the demand nodes, meaning that as the upper flow limits at the consumption points increase, the optimizer adjusts the flows along these pipelines accordingly, typically utilizing a larger fraction of their capacity. However, it is important to note an exception within this group: the pair formed by the upper flow bound at node $N_7$ and the flow through pipeline $p_3$ presents a negative linear relationship. In this case, an increase in the upper demand limit at $N_7$ is associated with a decrease in the use of pipeline $p_3$. This inverse behavior can be explained by the system's looped configuration, where $p_3$ contributes to a closed trajectory. Under higher demand at $N_7$, the optimizer might favor alternative paths that more directly satisfy the load, such as pipelines $p_5$ through $p_7$, reducing the role of $p_3$ in transporting gas.


\begin{figure}[H]
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_2.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a linear behavior, although with different dispersions among them. }\label{fig:joint_distributions_inputs_outputs_2}
\end{figure}
 


A final group of joint distributions worth highlighting is shown in \Cref{fig:joint_distributions_inputs_outputs_2_KDE}. Those involve input and output variables that exhibit a linear relationship, similar to the patterns observed in the optimization model. In particular, two of the joint PDFs show a positive correlation, where increases in the input variable are associated with proportional increases in the output. This behavior is seen in the pairs formed by the upper bound of the demand flow at node $N_6$ and the predicted flow in pipeline $p_4$, as well as between the same bound at node $N_7$ and the predicted flow in pipeline $p_5$. These relationships suggest that the network has captured a coherent system response, in which more flexible demand conditions at the consumption nodes lead to higher utilization of the pipelines supplying them, closely resembling the optimizer’s behavior. A third pair, formed by the upper demand bound at node $N_7$ and the flow in pipeline $p_3$, also shows a strong linear pattern, though in this case, the correlation is negative. This result mirrors the exception found in the optimization model, and can again be attributed to the presence of a loop in the network’s structure. Under increasing demand at $N_7$, the network tends to shift the flow away from pipeline $p_3$, likely in favor of more direct paths that connect to the demand node. This further confirms that the trained model replicates the general operating tendencies of the optimization scheme.

% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_2 KDE.png}
%     \end{center}
%     \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a linear behavior, although with different dispersions among them. }
%     \label{fig:joint_distributions_inputs_outputs_2_KDE}
% \end{figure}


This stochastic analysis conducted in the study provided a view of how input uncertainties propagate through the natural gas network and shape the behavior of output variables. By examining the joint probability distributions among inputs, among outputs, and between inputs and outputs, it was possible to uncover structural dependencies, dominant operating regimes, and regions of stability or variability within the system. The presence of strong correlations in certain areas, such as between upstream injection pressures and downstream demands, as well as the identification of operational preferences, like the consistent underutilization of specific pipelines, demonstrate the model’s ability to capture operational behavior. 

% An additional stochastic analysis was performed to assess further the robustness of the trained GNN-based model and its ability to generalize under uncertainty. This analysis is motivated by the need to simulate and evaluate the model's responses in scenarios that were not explicitly present in the training data, thereby providing a means to quantify the variability and reliability of the model's predictions. Initially, a kernel density estimate (KDE) was fitted to the input training data used for the GNN model. From this estimated distribution, a set of synthetic input samples, denoted as \( X_{\text{sample}} \), was generated. These synthetic inputs were then propagated forward through the trained network, taking into account all loss components, to yield a corresponding set of output predictions, denoted as \( y_{\text{sample}} \). In parallel, the original training inputs were propagated through the network to obtain output predictions, denoted as \(\bar{y}_{\text{train}}\). A second KDE was then fitted using the training output data (hereafter referred to as \(y_{\text{train}}\)). Two log-likelihoods were calculated based on this second KDE: one using \(y_{\text{sample}}\) and the other using \(\bar{y}_{\text{train}}\). The log-likelihood for the synthetic outputs, \(y_{\text{sample}}\), was found to be \(-6,696,247.56\), while the log-likelihood for the training outputs, \(\bar{y}_{\text{train}}\), was \(-6,657,534.62\). The closeness of these two values suggests that the synthetic outputs generated from the input KDE closely resemble the distribution of the training outputs.
%
% To further evaluate the goodness-of-fit between the distributions of \( y_{\text{sample}} \) and \( \bar{y}_{\text{train}} \), a Kolmogorov–Smirnov (K–S) test was conducted using three alternatives: two-sided, less, and more significant. The test results were as follows: a two-sided test yielded a statistic of \( 0.01833 \) with a p-value of \( 0.81482 \) (statistic location \(-0.34018\); the 'less' alternative produced a statistic of \( 0.01167 \) with a p-value of \( 0.72137 \) (statistic location \(0.30738\); and the 'greater' alternative returned a statistic of \( 0.01833 \) with a p-value of \( 0.44640 \) (statistic location \(-0.34018\). These statistical measures provide an initial indication that the synthetic outputs generated via the KDE-based sampling are consistent with the distribution of outputs observed during training, thereby supporting the model's capability to generalize to new, unseen scenarios. After completing the stochastic analysis of the variables associated with the optimization model, the next step involves leveraging the KDE fitted to the training data. This fitted KDE was used to generate a new set of input samples that represent the learned probability distribution of the optimization model's inputs. These samples were then forward propagated through the trained neural network model. Using the resulting network outputs, a new joint analysis was conducted, analogous to the previous one performed with the variables of the optimization model. 
%
% % Following the same structure presented in the first part of this analysis, we begin by highlighting the relationships that exhibit two distinct modes of operation according to their joint probability density functions. In this case, as shown in Figure~\cref{fig:joint_distributions_input_input_KDE}, only two variable pairs present this bimodal behavior when the analysis is performed using the inputs propagated through the trained neural network. These pairs are: the nodal pressure limits of $N_4$ and $N_2$, and those of $N_6$ and $N_5$. In both cases, the joint PDFs suggest the existence of two operational regimes, potentially associated with alternative configurations or routing strategies within the network that are learned by the neural model. 
%
%
% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=0.75\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs (Sampled).png}
%     \end{center}
%     \caption{Joint PDFs between the entries used in the 8-node network, which have two modes in the KDE sampled variables}
%     \label{fig:joint_distributions_input_input_KDE}
% \end{figure}
%      

% Continuing with the distributions that exhibit a small high-probability region (\Cref{fig:joint_distributions_input_input_no_mode_KDE}), three pairs of variables were identified in this case whose joint PDFs display this characteristic. These pairs are: The Upper injection limit and the nodal pressure limits between $N_0$ and $N_1$; the pressure limits between $N_1$ and $N_4$; and the gas flow demand in $N_6$ and the nodal pressure limit in $N_4$. These distributions are characterized by a concentrated and sharply defined region of high probability, suggesting that the neural network tends to favor very specific combinations of input values during prediction. It is worth noting that, unlike in the previous analysis based on the optimization model, no distributions with broad and clearly defined high-probability zones (i.e., darker and more extensive areas) were observed.
%
% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=.75\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_no_mode (KDE).png}
%     \end{center}
%     \caption{Joint PDFs between the inputs used in the 8-node network, which do not appear to have a defined mode in the KDE sampled variables. }
%     \label{fig:joint_distributions_input_input_no_mode_KDE}
% \end{figure}


% \Cref{fig:joint_distributions_output_output_2_KDE} shows a group of joint probability density functions that resembling bivariate gamma distributions. A particularly noteworthy feature across these plots is the behavior of the flow transported through pipeline $p_3$, the segment that closes the loop in the system's topology. In all distributions, this variable (shown along the X-axis) assumes negative values, typically ranging between 10\% and 30\% of its normalized capacity. This negative trend can be interpreted as the network has learned that, under optimal conditions, the flow through pipeline $p_3$ should operate in the direction opposite to the one originally assumed in the problem formulation. The reversal in direction is not only coherent with the physical and economic constraints of the system but also mirrors the behavior found in the optimization model. Furthermore, this pattern is robust across a diverse set of operating scenarios, as evidenced by the variables plotted along the Y-axis, which include the total injection at node $N_0$ and the flows through pipelines $p_0$, $p_1$, $p_2$, $p_4$, and $p_5$. 
%
%
%
% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=.65\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_2 (KDE).png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which have a negative flow in the KDE sampled variables.}
%     \label{fig:joint_distributions_output_output_2_KDE}
% \end{figure}
 


% Continuing with the comparison, PDFs consist of input and output variables that present a similar pattern to that observed in the optimization model that appears in the neural network predictions. As shown in \Cref{fig:joint_distributions_inputs_outputs_1_KDE}, there is a group of joint probability distributions where the input variables span a wide range of values, while the corresponding output,specifically, the flow through pipeline $p_4$, remains narrowly concentrated between 20\% and 40\% of its normalized capacity. This behavior mirrors what was previously discussed for the optimization model, suggesting that, even under the learned data distribution, the network consistently predicts a relatively low and stable utilization of this particular pipeline. The pairs exhibiting this characteristic include the upper bound on injection flow at node $N_0$ and the upper bounds on nodal pressures at nodes $N_0$ through $N_7$, all compared against the predicted flow through pipeline $p_4$. As in the previous case, normalization was only applied to the output variables, while the inputs were left in their original scale. The similarity in joint distribution patterns between the optimization model and the neural network predictions indicates that the trained model effectively internalized a similar resolution strategy, favoring stable usage of pipeline $p_4$ regardless of the variability in input conditions.
%
%
% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_1 KDE.png}
%     \end{center}
%     \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a wide dispersion along second variable. }
%     \label{fig:joint_distributions_inputs_outputs_1_KDE}
% \end{figure}




% A final group of joint distributions worth highlighting is shown in \Cref{fig:joint_distributions_inputs_outputs_2_KDE}. Those involve input and output variables that exhibit a linear relationship, similar to the patterns observed in the optimization model. In particular, two of the joint PDFs show a positive correlation, where increases in the input variable are associated with proportional increases in the output. This behavior is seen in the pairs formed by the upper bound of the demand flow at node $N_6$ and the predicted flow in pipeline $p_4$, as well as between the same bound at node $N_7$ and the predicted flow in pipeline $p_5$. These relationships suggest that the network has captured a coherent system response, in which more flexible demand conditions at the consumption nodes lead to higher utilization of the pipelines supplying them, closely resembling the optimizer’s behavior. A third pair, formed by the upper demand bound at node $N_7$ and the flow in pipeline $p_3$, also shows a strong linear pattern, though in this case, the correlation is negative. This result mirrors the exception found in the optimization model, and can again be attributed to the presence of a loop in the network’s structure. Under increasing demand at $N_7$, the network tends to shift the flow away from pipeline $p_3$, likely in favor of more direct paths that connect to the demand node. This further confirms that the trained model replicates the general operating tendencies of the optimization scheme.
%
% \begin{figure}[htbp]
%     \begin{center}
%         \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_2 KDE.png}
%     \end{center}
%     \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a linear behavior, although with different dispersions among them. }
%     \label{fig:joint_distributions_inputs_outputs_2_KDE}
% \end{figure}






\subsection{Case Study II: 63-node Network (Colombia)}


This section addresses the second case study, focusing on the Colombian natural gas network. As in the previous cases, this analysis explores various configurations of loss function to evaluate the predictive performance of the CensNet-based model. The first experiment examines the model's predictive capabilities when incorporating node and edge losses.

This experiment used optimized hyperparameters, with \( N \ channels = 21 \), \( N \ layers = 5 \), and \( N \ dense = 4 \), which were selected to enhance the model's performance. The experiment yielded a total loss of \( 267.6 \), encompassing node and edge losses, along with a calculated balance loss. Specifically, the node loss reached \( 17.5 \), while the edge loss was considerably higher at \( 250.1 \). Additionally, a balance loss of \( 338.7 \) was recorded. Notably, the balance loss was calculated to assess network consistency but was not incorporated into the model's cost function during training; instead, it serves as an independent evaluation metric. 


The CensNet-based model's predictive accuracy in this experiment was quantified using \( R^2 \) metrics, and the results are shown in \Cref{fig:col_base_f_results_non_lineal}. The nodal predictions exhibited high accuracy, with an \( R^2 \) score of \( 0.993 \) in \Cref{fig:results_nonlineal_col_node_base_f}, indicating that the model closely approximates the observed nodal flow values. Similarly, the edge predictions achieved an \( R^2 \) score of \( 0.963 \), demonstrating robust performance in predicting edge flows. This last value can be seen in \Cref{fig:results_nonlineal_col_edge_base_f}.


\begin{figure}[htbp]
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_f.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_f.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flows in the Colombian case network.}
    \label{fig:col_base_f_results_non_lineal}
\end{figure}


The second experiment evaluated the CensNet-based model, focusing on losses associated with nodes and balance. Using the optimized hyperparameters \( N \ channels = 49 \), \( N \ layers = 5 \), and \( N \ dense = 2 \), the model yielded a total loss of \( 24.9 \). This loss value includes a node loss of \( 17.02 \), a calculated edge loss of \( 2,912.2 \), and a balance loss of \( 7,9 \). In this experiment, only the node and balance losses were included in the model's cost function, while the edge loss was computed independently to assess prediction accuracy for edge flows.


\begin{figure}[htbp]
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_bal.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_bal.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance and Weymouth losses in the Colombian case network.}
    \label{fig:col_base_bal_results_non_lineal}
\end{figure}



The predictive accuracy, evaluated using \( R^2 \) metrics, yielded \( R^2 = 0.993 \) for nodal predictions and \( R^2 = 0.57 \) for edge predictions, as shown in \Cref{fig:results_nonlineal_col_node_base_bal} and \Cref{fig:results_nonlineal_col_edge_base_bal}. The scatterplot in \Cref{fig:results_nonlineal_col_node_base_bal} illustrates the accuracy of nodal predictions, with predicted values aligning closely to the true values. In contrast, the scatterplot in \cref{fig:results_nonlineal_col_edge_base_bal} reveals less consistency in edge predictions, likely due to the exclusion of edge loss from the cost function. Although a general linear trend is observable between predicted and true values in this scatterplot, a notable number of inaccurately predicted values diminish the overall \( R^2 \), impacting the edge loss and prediction accuracy.







The third experiment evaluated the CensNet-based model's predictive capabilities by incorporating losses associated with nodes, edges, and balance. With the optimized hyperparameters \( N \ channels = 20 \), \( N \ layers = 5 \), and \( N \ dense = 2 \), the model achieved a total loss of \( 347.7 \), including a node loss of \( 37.7 \), an edge loss of \( 264.2 \), and a balance loss of \( 45.8 \). This experiment integrated all three losses into the model's cost function, allowing a more comprehensive assessment of its predictive performance.

The predictive accuracy was quantified by \( R^2 \) values of \( 0.984 \) and \( 0.961 \) for nodes and edges, respectively, as shown in \Cref{fig:results_nonlineal_col_node_base_f_bal} and \Cref{fig:results_nonlineal_col_edge_base_f_bal}. In these scatterplots, the predictions demonstrate a clearer alignment with the true values, with both graphs illustrating shapes more similar to straight lines, which indicates improved model performance in capturing the underlying patterns of nodal and edge flows.


\begin{figure}[htbp]
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_f_bal.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_f_bal.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance loss in the Colombian case network.}
    \label{fig:col_base_f_bal_results_non_lineal}
\end{figure}



This third experiment marks the final test conducted in this study. Attempts to include the Weymouth loss were hindered by significant computational complexity, preventing the acquisition of reliable results for the model when considering the Weymouth function loss. Therefore, further tests were not feasible within the current scope.



% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
%     \hline
%     Method & \centering N & \centering E & \centering B & \centering W & Node Value & Edge Value & Balance Value & Time \\ \hline
%     \textbf{Base} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & & & & \( 11.22 \pm 49.03 \) & \( 62.73 \pm 81.99 \) & \( -2.28 \pm 25.48 \) &  \\ \hline
%     \textbf{Base bal} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & & \( 12.47 \pm 48.90 \) & \( 88.32 \pm 73.55 \) & \( -1.03 \pm 1.90 \) &  \\ \hline
%     \textbf{Base f Bal} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 12.33 \pm 48.64 \) & \( 63.06 \pm 81.32 \) & \( -1.17 \pm 7.38 \) &  \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, and nodal balance between IPOPT and GNN across different loss configurations. The columns "N", "E", and "B" indicate experiments where nodal, edge, and balance losses were considered.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}
%

%
% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
%     \hline
%     Method & \centering N & \centering E & \centering B & Node Value & Edge Value & Balance Value & Time \\ \hline
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) & \( 13.65 \pm 2.86 \) \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.22 \pm 49.03 \) & \( 62.73 \pm 81.99 \) & \( -2.28 \pm 25.48 \) & \( 0.15 \pm 0.04 \) \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 12.47 \pm 48.89 \) & \( 88.32 \pm 73.55 \) & \( -1.03 \pm 1.90 \) & \( 0.15 \pm 0.05 \) \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \( 12.33 \pm 48.64 \) & \( 63.06 \pm 81.32 \) & \( -1.17 \pm 7.38 \) & \( 0.15 \pm 0.04 \) \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, nodal balance, and prediction time between IPOPT and GNN across different loss configurations. The columns "N", "E", and "B" indicate experiments where nodal, edge, and balance losses were considered.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}
%
%
% The \cref{tab:base_nl_dummy_results_formatted} provides a comparison between the IPOPT optimization model and the GNN-based model across four experiments that incorporate different combinations of nodal (N), edge (E), and balance (B) losses. The results focus on nodal flows, edge flows, nodal balance, and prediction time, with mean and standard deviation values.
%
% In this table, the IPOPT model serves as the baseline. It achieves a nodal flow mean of \( 11.32 \pm 48.89 \), an edge flow mean of \( 63.38 \pm 83.11 \), and a balance value mean of \( -2.18 \pm 29.78 \). The prediction time for this benchmark model is \( 13.65 \pm 2.86 \) seconds, providing a standard for comparison with GNN-based models.
%
% The first GNN experiment considers only the nodal loss. It produces a nodal flow mean of \( 11.22 \pm 49.03 \), closely aligning with the IPOPT nodal flow. The edge flow mean, at \( 62.73 \pm 81.99 \), is also similar to IPOPT's results. The balance value mean of \( -2.28 \pm 25.48 \) shows moderate variability, while the GNN's prediction time is notably faster, at \( 0.15 \pm 0.04 \) seconds.
%
% In the second GNN experiment, both nodal and edge losses are incorporated. The nodal flow prediction mean slightly increases to \( 12.47 \pm 48.89 \), while the edge flow mean shows a more significant increase, reaching \( 88.32 \pm 73.55 \). The balance value improves in consistency, with a mean of \( -1.03 \pm 1.90 \), and the prediction time remains low at \( 0.15 \pm 0.05 \) seconds, indicating efficient computation.
%
% The third GNN experiment includes nodal, edge, and balance losses. Here, the nodal flow means it is \( 12.33 \pm 48.64 \), and the edge flow means returns to a closer alignment with IPOPT at \( 63.06 \pm 81.32 \). The balance value stabilizes, reaching \( -1.17 \pm 7.38 \), while the prediction time remains consistent at \( 0.15 \pm 0.04 \) seconds.
%
% This table illustrates the GNN model's capability to maintain accurate predictions and achieve lower computational time than IPOPT, especially when incorporating more loss components.
%


% \begin{table}[htbp]
% \centering
% \begin{tabular}{|l|c|c|c|c|}
%     \hline
%     Method & Node Value & Edge Value & Balance Value & Time \\ \hline
%     IPOPT & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) & \( 13.65 \pm 2.86 \) \\ \hline
%     GNN (N) & \( 11.22 \pm 49.03 \) & \( 62.73 \pm 81.99 \) & \( -2.28 \pm 25.48 \) & \( 0.15 \pm 0.04 \) \\ \hline
%     GNN (N+E) & \( 12.47 \pm 48.89 \) & \( 88.32 \pm 73.55 \) & \( -1.03 \pm 1.90 \) & \( 0.15 \pm 0.05 \) \\ \hline
%     GNN (N+E+B) & \( 12.33 \pm 48.64 \) & \( 63.06 \pm 81.32 \) & \( -1.17 \pm 7.38 \) & \( 0.15 \pm 0.04 \) \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, nodal balance, and prediction time between IPOPT and GNN-based models under different loss configurations for the Colombian natural gas system. The notation \textbf{GNN (N)} indicates the use of nodal loss only, while \textbf{GNN (N+E)} and \textbf{GNN (N+E+B)} incorporate additional edge and balance losses respectively.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}



\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
    \hline
    Method & Node Error & Edge Error & Balance Error & Time \\ \hline
    CensNet(N) & \( 0.10 \pm 69.24 \) & \( 0.65 \pm 116.75 \) & \( 0.10 \pm 39.19 \) & \( 13.50 \pm 2.86 \) \\ \hline
    CensNet(N+E) & \( -1.15 \pm 69.14 \) & \( -24.94 \pm 110.98 \) & \( -1.15 \pm 29.84 \) & \( 13.50 \pm 2.86 \) \\ \hline
    CensNet(N+E+B) & \( -1.01 \pm 68.96 \) & \( 0.32 \pm 116.28 \) & \( -1.01 \pm 30.68 \) & \( 13.50 \pm 2.86 \) \\ \hline
\end{tabular}
\caption{Differences in mean and standard deviation between IPOPT and CensNet-based models for nodal flows (Node Error), edge flows (Edge Error), nodal balance (Balance Error), and prediction time (Time) in the Colombian natural gas system. Each value represents the difference IPOPT - CensNet.}
\label{tab:gnn_differences_results}
\end{table}



The results in \Cref{tab:gnn_differences_results} show the differences between the IPOPT benchmark and the CensNet models applied to the Colombian natural gas network. As with the synthetic case, all CensNet configurations offer a significant advantage in prediction time, maintaining fast inference across all loss settings.

When trained with only the nodal loss (CensNet (N)), the model achieves low nodal error and a moderate edge error. However, the balance error remains relatively high, suggesting that nodal supervision alone is insufficient to enforce global consistency. Incorporating the edge loss (CensNet (N+E)) unexpectedly worsens the edge error. Further, it increases the balance error, indicating that without additional physical constraints, the model may overfit local patterns at the expense of system-wide coherence.

Adding the balance loss (CensNet (N+E+B)) improves edge predictions significantly, reducing the edge error from \(-24.94\) to \(0.32\), while also recovering a more accurate balance prediction. Although the nodal error remains similar, this configuration yields the best trade-off between nodal, edge, and balance accuracy.

Among the evaluated settings, \textbf{CensNet (N+E+B)} delivers the most physically consistent results, closely approximating the IPOPT benchmark while preserving the CensNet model’s computational advantage.


An uncertainty analysis similar to the previous case was performed for the Colombian natural gas transportation network. Using the same methodology, a second kernel density estimate (KDE) was fitted to the training output data, and synthetic outputs were generated. The log-likelihood computed from the synthetic outputs was \(-104{,}413{,}419.34\), while that from the training outputs was \(-104{,}037{,}047.58\). To further assess the similarity between the two distributions, a Kolmogorov–Smirnov (K–S) test was conducted under three different alternatives: two-sided, less, and greater. The results were as follows: for the two-sided alternative, the test statistic was \(0.00527\) with a p-value of \(0.95556\) (statistic location \(0.52109\)); for the less alternative, the test statistic was \(0.00527\) with a p-value of \(0.59061\) (statistic location \(0.52109\)); and for the greater alternative, the test statistic was \(0.00324\) with a p-value of \(0.81777\) (statistic location \(-0.73443\)). These findings indicate a high degree of similarity between the synthetic and training outputs, as the low test statistics and high p-values suggest that the two distributions are statistically indistinguishable. The slight differences in log-likelihood values further confirm that the synthetic data effectively capture the essential characteristics of the training data, thereby validating the robustness of the stochastic sampling approach for this network.





\section{Discussion}


% This chapter's first set of experiments provides insights into the model's capability to handle gas network predictions with various loss function combinations. Including node and edge losses in the initial experiment demonstrated the model's capacity to accurately capture node behavior, as evidenced by a high $R^2$ value of 0.983 for nodal flow predictions. This result indicates the model's ability to learn injection patterns at the nodes, even under nonlinear system conditions.
%
% Incorporating the gas balance loss in subsequent experiments maintained the accuracy of nodal predictions, with no notable change in the $R^2$ for node flows. However, the slight reduction in the $R^2$ for edge flows to 0.973 suggests that while the gas balance constraint improved overall network consistency, it introduced additional complexity that slightly affected edge prediction performance. This outcome highlights a trade-off between accurate node predictions and balanced edge flows, indicating robust model performance with some sensitivity to changes in loss function configurations.
%
% Further exploration of the model's response to including the Weymouth equation loss introduced more pronounced effects, particularly on edge flow predictions. The decline in $R^2$ to 0.952 for edge flows indicates increased difficulty in accurately modeling flow through specific network paths, particularly in regions with closed loops or compressor installations. This outcome underscores the challenge of incorporating multiple nonlinear physical constraints, especially in complex configurations.
%
% In the experiment where only the Weymouth equation and node losses were considered, the model maintained a high $R^2$ for nodal flows. However, the extremely low $R^2$ for edge predictions, reaching negative values, suggests the model struggled to generalize edge flows effectively when isolated from balancing and edge losses. This finding reinforces the need for a comprehensive loss framework incorporating node and edge dynamics to ensure robust network performance, highlighting the challenges of predicting edge flows under limited constraints.
%
% Comparing the results from \cref{cap:lienal-censnet} with those in \cref{cap:non_linealcensnet} reveals that the addition of physical constraints in \cref{cap:non_linealcensnet} improves model performance, particularly in terms of balancing accuracy.
%
% The losses presented in \cref{cap:lienal-censnet} (Table \ref{tab:lineal_dummy_results}) reflect initial configurations with only nodal and edge losses. In these setups, while nodal and edge values show reasonable consistency with the APOPT optimizer, the balance values exhibit higher variability, especially in the GNN configurations. For example, when both nodal and edge losses are applied, the GNN model in \cref{cap:lienal-censnet} produces a balance error of \(-5.711 \pm 16.854\), which differs significantly from the APOPT optimizer's near-zero balance error (\(-0.001 \pm 0.038\)). This difference indicates that the simpler GNN models in \cref{cap:lienal-censnet} lack additional constraints to replicate the physical conditions accurately.
%
% In \cref{cap:non_linealcensnet}, adding constraints related to balance and the Weymouth equation (Table \ref{tab:base_nl_dummy_results_formatted}) leads to improved balance accuracy. For instance, the GNN model with nodal, edge, and balance losses achieves a balance error of \(0.004 \pm 0.845\), considerably lower and more consistent with the IPOPT optimizer. This improvement demonstrates how adding balance constraints reduces variability and error associated with balance. Additionally, GNN configurations that include balance and Weymouth constraints (i.e., N, E, B, W) sustain this balance improvement while closely aligning with APOPT, which results in nodal and edge values.
%
%
% In the second experiment, the performance of the GNN-based model was evaluated in three configurations with different combinations of loss functions applied to the Colombian natural gas network. For each configuration, it was possible to consider the nodal losses, the losses associated with the edges, and the gas balance dede. The analysis provides information on the trade-offs and improvements observed with each additional loss function.
%
% The first configuration of the GNN model, which incorporated nodal and edge losses, achieved high accuracy in predicting nodal flows with an $R^2$ score of $0.993$ while maintaining an edge prediction $R^2$ of $0.963$. This configuration showed strong performance in nodal predictions,  suggesting that focusing on this loss combination allows a good approximation of nodal flows in the system. The balance loss value, calculated independently, highlighted minimal deviation, indicating that nodal accuracy alone could achieve network consistency for this setup. These results underscore the model's capacity to generalize nodal flow predictions while capturing nodal behaviors, making this configuration efficient for applications where nodal flow prediction is prioritized.
%
% The second configuration evaluated the impact of including nodal and balance losses in the model's cost function. The results demonstrated a stable nodal prediction performance, with an $R^2$ score consistent at $0.993$, while edge predictions dropped to an $R^2$ of $0.569$. This reduction in edge prediction accuracy suggests that excluding edge loss from the cost function introduced inconsistencies in the edge flows, as reflected in the decreased $R^2$ value. Despite the moderate accuracy in edge flow predictions, the balance loss value remained relatively low, indicating stable nodal balance but highlighting a trade-off when optimizing only nodal and balance aspects. 
%
%
% In the third configuration, the GNN model included all three loss types: nodal, edge, and balance. This approach achieved a slightly lower $R^2$ of $0.984$ for nodal predictions but improved the edge prediction accuracy, yielding an $R^2$ of $0.961$. The overall alignment of predictions observed in the scatterplots suggests that incorporating all three loss functions enabled the model to more comprehensively capture the patterns of both nodal and edge flows. This approach demonstrated the most balanced trade-off between nodal and edge prediction accuracy, supporting the hypothesis that optimizing all three aspects simultaneously enhances the model's capacity to predict flows in the Colombian natural gas network. 
%
%
%
% Finally, the performance of the GNN-based model for the Colombian natural gas network is compared in two experimental configurations: Chapter 2 and Chapter 4. Each experiment considered nodal, edge, and balance loss combinations, assessing their effects on prediction accuracy and computational efficiency. Notably, due to high computational demands, the experiments in Chapter 4 did not include the Weymouth equation loss.
%
% In Chapter 2 (Table \ref{tab:lineal_col_results}), the GNN-based model, when only the nodal loss was applied, achieved a Node Value of \(11.38 \pm 49.13\) and an Edge Value of \(0.91 \pm 1.26\), with a Balance Value of \(-2.19 \pm 58.56\). The model showed relatively high accuracy in nodal predictions and achieved minimal edge prediction errors, highlighting the model’s effectiveness in capturing nodal flows without explicitly optimizing for edge loss.
%
% In Chapter 4 (Table \ref{tab:base_nl_dummy_results_formatted}), the experiments showed varied performance depending on the losses included:
%
% 1. In the configuration considering only nodal loss, the GNN achieved a Node Value of \(11.22 \pm 49.03\) and an Edge Value of \(62.73 \pm 81.99\), with a Balance Value of \(-2.28 \pm 25.48\). Compared to Chapter 2, this configuration demonstrated a higher edge error, suggesting that solely optimizing nodal loss did not generalize as effectively for edge predictions as observed previously.
%
% 2. When both nodal and edge losses were included, the GNN model’s Node Value increased to \(12.47 \pm 48.89\), with a significant rise in Edge Value error to \(88.32 \pm 73.55\). The Balance Value was reduced to \(-1.03 \pm 1.90\), indicating improved nodal balance but an unfavorable impact on edge prediction. This result diverges from Chapter 2, where the inclusion of edge loss contributed to more consistent results in both nodal and edge values.
%
% 3. In the configuration considering nodal, edge, and balance losses, the GNN model achieved a Node Value of \(12.33 \pm 48.64\), with an Edge Value of \(63.06 \pm 81.32\) and a Balance Value of \(-1.17 \pm 7.38\). This approach achieved better balance accuracy but did not markedly improve edge error over configurations excluding balance loss, contrasting with Chapter 2, where combined losses had more favorable outcomes.
%
% Across both chapters, it is clear that optimizing for multiple loss functions introduces complexity, with varied impacts on nodal and edge prediction accuracy. The Chapter 4 results indicate that including balance and edge losses improves nodal balance but can lead to edge-accuracy trade-offs. Further optimization strategies or alternative methods may be required to balance all metrics.
%
%
% The stochastic analysis performed on the 8-node network provided valuable insights into the inherent uncertainty of the system. By fitting a kernel density estimate (KDE) to the training input data and generating synthetic input samples (\(X_{\text{sample}}\)), these were propagated through the trained network to obtain corresponding outputs (\(y_{\text{sample}}\)). A second KDE was then fitted to the training outputs (\(y_{\text{train}}\)), and log-likelihood values were computed for both \(y_{\text{sample}}\) and the outputs derived from the training inputs (\(\bar{y}_{\text{train}}\)). The proximity of these log-likelihood values, along with high p-values and low test statistics from the Kolmogorov–Smirnov tests, confirms that the synthetic outputs closely mirror the original training output distribution. This result validates the stochastic sampling approach and indicates that the model accurately captures the underlying data distribution, enabling rapid evaluation of new scenarios.
%
% A similar stochastic analysis was conducted on the Colombian natural gas network. In this case, the log-likelihood computed from the synthetic outputs was \(-104,413,419.34\) compared to \(-104,037,047.58\) for the training outputs. The Kolmogorov–Smirnov tests, performed under various alternatives, yielded low test statistics and high p-values, further supporting the similarity between the two distributions. These outcomes underscore the robustness of the stochastic framework, demonstrating that the trained model generalizes well to new, unseen scenarios. Consequently, the approach enhances the understanding of model uncertainties and provides a reliable basis for rapid scenario analysis and uncertainty quantification of natural gas network operations.
%


This chapter has explored the predictive capabilities of a CensNet-based model for gas network simulation under various loss function configurations. The results emphasize the importance of designing loss functions that integrate physical and operational constraints in order to improve the model's ability to generalize and maintain consistency across different components of the network.

The initial experiments in the 8-node gas system confirmed that nodal loss alone is sufficient for capturing nodal flow patterns, particularly under nonlinear conditions. However, when edge or balance losses are added, the model gains the ability to replicate more complex network dynamics. This trade-off between precision in nodal predictions and general system consistency reveals the flexibility of the CensNet model and its responsiveness to different training objectives. Incorporating edge loss helps improve flow predictions, while balance constraints contribute to system-wide consistency, even if they occasionally introduce minor trade-offs in prediction accuracy.


The inclusion of the Weymouth equation loss proved to be more challenging due to its nonlinear nature. Its integration caused a noticeable decrease in edge prediction accuracy, particularly in regions with compressors and closed loops, highlighting the difficulty of aligning learned representations with complex physical equations. These findings underline the need for careful calibration when physical constraints are introduced into data-driven models.

A comparative analysis of the CensNet model across linear and nonlinear cases further emphasizes the benefits of incorporating physical knowledge. The results from the nonlinear case showed improved balance accuracy, suggesting that physically-informed constraints can enhance the model’s ability to simulate realistic operating conditions. While nodal and edge predictions remained consistent across chapters, the balance constraint had a particularly beneficial effect, reducing variability and error without compromising computational efficiency.

For the 8-node case, the study was complemented with an in-depth probabilistic analysis of the model's outputs. This involved examining the joint distributions of selected variables and revealed patterns of interdependence between operational variables, such as nodal pressures and flows through pipelines or compressors. These findings confirmed that the trained model not only learned the mapping between inputs and outputs but also preserved structural dependencies across the network.

When applied to the Colombian natural gas network, the CensNet model displayed consistent behavior across different combinations of losses. Including nodal and edge losses yielded strong performance in nodal predictions, with minimal deviation in balance, suggesting that such configurations are effective in applications where nodal flow is prioritized. Introducing balance constraints improved system consistency while maintaining strong overall performance.

To assess generalization under uncertainty, a stochastic framework was applied to both networks. Synthetic input samples were generated using kernel density estimation (KDE) and propagated through the trained model. The outputs were then compared with those from the training data using log-likelihood estimates and Kolmogorov–Smirnov (K–S) tests under three alternatives: two-sided, less, and greater. In both cases, the close match between the distributions, reflected in similar log-likelihood values and non-significant K–S statistics, validated the consistency and robustness of the trained model under unseen conditions. These results support the idea that the model has internalized features of the data distribution and can provide reliable predictions beyond the training set.


By validating the ability of the CensNet model to approximate system behavior under uncertainty, and by showing how stochastic sampling can be used to evaluate the variability of decision-relevant outputs, this work enables the formulation of optimization strategies that move beyond deterministic dispatch. The integration of uncertainty quantification into the modeling process lays the groundwork for decision-making frameworks that are robust under data variability and can be aligned with the operational constraints of gas transport systems. As such, the developments presented here represent a step toward the implementation of a stochastic gas flow optimization strategy for real-world applications.


