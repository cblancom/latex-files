% \chapter{Enhanced Natural Gas Flow Predictions Using Physics-Guided Neural Networks} 
\chapter{Stochastic Modeling of Natural Gas Flows Using Physics-Guided Neural Networks} \label{cap:non_linealcensnet}

% While the GNN-based model from \cref{cap:lienal-censnet} was designed as a fast alternative to the optimization-based model, this chapter introduces physics-informed elements into the network architecture. Specifically, the model now includes loss terms based on the gas balance and Weymouth equations to ensure the predicted flows comply with the physical laws governing gas transportation. These constraints, integrated through additional layers in the model, guide the learning process, penalizing deviations from the gas balance equation (\cref{eq:gas_balance}) and the Weymouth equation (\cref{eq:weymouth_cons}). The modified model maintains the same structural components, such as input channels, convolutional layers, and loss functions for node and edge predictions, with the difference that the balance equation and the Weymouth equation are now considered loss functions. 
This chapter aims to explore the integration of physical knowledge and stochastic modeling into graph-based neural network architectures to improve natural gas flow predictions under uncertainty. Building upon previous deterministic configurations, the proposed approach introduces physical constraints, such as nodal balances and the Weymouth equation, directly into the model’s loss function to enhance prediction accuracy. Additionally, a stochastic framework is developed to quantify the uncertainty in both objective and decision variables related to gas system operations. Through a series of experiments, including applications to a simplified 8-node network and the Colombian national gas network, the chapter evaluates the trade-offs introduced by different loss function combinations It demonstrates the model’s ability to generalize under stochastic sampling, thereby advancing the development of a physics-guided and uncertainty-aware gas dispatch optimization strategy.


\section{Methodology}

Physics-Informed Neural Networks (PINNs) represent a class of neural networks where physical laws are incorporated into the learning process, guiding the model to respect these constraints. Unlike traditional neural networks, where the loss function is typically based on the discrepancy between predicted and actual data, PINNs introduce additional terms in the loss function that penalize the model for deviating from known physical principles.

In this case, the physical constraints are derived from the gas balance and the Weymouth equations, which describe the flow and pressure behavior within the gas transportation network. These constraints are integrated into the neural network model introduced in \Cref{cap:lienal-censnet} as additional loss terms. Specifically, we define two layers within the network: one that calculates the error in gas balance and another that calculates the error in the Weymouth equation. The outputs of these layers are then used to adjust the network's predictions, ensuring that they adhere to the physical laws governing the system.

The inclusion of these physics-informed layers allows the network to achieve better generalization, as it is not only trained on the data but also guided by the underlying physical laws. This approach can be seen as a specialized form of regularization, where the model is penalized if its predictions do not satisfy the physical constraints. The overall loss function can be expressed as:

\begin{equation}
   \mathcal{J}(\Theta) = \mathcal{J}_{\text{data}}(\Theta) +  \mathcal{J}_{\text{balance}}(\Theta) +  \mathcal{J}_{\text{weymouth}}(\Theta),     
    \label{eq:PINN_basic_definition}
\end{equation}

\noindent with \( \mathcal{J}_{\text{data}}(\Theta) \) represents the traditional data-driven loss, \( \mathcal{J}_{\text{balance}}(\Theta) \) is the loss associated with the gas balance constraint, and \( \mathcal{J}_{\text{weymouth}}(\Theta) \) is the loss associated with the Weymouth equation constraint. 



The gas balance constraint is enforced at each node through the following loss function:

\begin{equation} \label{eq:gas_balance_GNN}
\mathcal{J}_{\text{balance}} =  \mathbf{T} \cdot \hat{\mathbf{f}}_e - \mathbf{d} + \hat{\mathbf{f}}_n .
\end{equation}

\noindent In here \( \hat{\mathbf{f}}_e \in \mathbb{R}^{N_e} \) is the predicted edge flow, \( \hat{\mathbf{f}}_n \in \mathbb{R}^{N_v} \) is the predicted nodal injection, and \( \mathbf{d} \in \mathbb{R}^{N_v} \) is the actual demand. The associated loss is given by:


The Weymouth constraint relates the gas flow to the difference of squared pressures between connected nodes through this loss function:

\begin{equation} \label{eq:Weymouth_GNN}
\mathcal{J}_{\text{weymouth}} =  \mathbf{M}_{\mathcal{P}} \left( \hat{\mathbf{f}}_e^{\circ 2} - \mathbf{K} \circ \left( \mathbf{T} \cdot \hat{\boldsymbol{\pi}}^{\circ 2} \right) \right),
\end{equation}


\noindent with \( \hat{\boldsymbol{\pi}} \in \mathbb{R}^{N_v} \) is the predicted pressure at each node, \( \hat{\mathbf{f}}_e^{\circ 2} \) is the element-wise square of edge flows, \( \mathbf{T} \in \mathbb{R}^{N_e \times N_v} \) is the signed incidence matrix, the vector \( \mathbf{K} \in \mathbb{R}^{N_e} \) contains the Weymouth constants for each edge and is zero for compressors, and \( \mathbf{M}_{\mathcal{P}} \in \mathbb{R}^{N_e \times N_e} \) is a diagonal matrix that selects only the pipeline edges \( p \in \mathcal{P} \).

Together, these physics-informed components guide the neural network toward solutions that not only fit the data but also obey the operational and physical laws of gas transport.


In this chapter, we build upon the experimental setup outlined in \Cref{sec:LinealCensnet_ExperimentalSetup}, maintaining the same general approach while incorporating new elements that account for the physics of the natural gas system represented in \Cref{eq:gas_balance_GNN,eq:Weymouth_GNN} following the scheme shown in \Cref{fig:nonlineal_model_description}. The samples are generated using the nonlinear natural gas network optimization model from \Cref{cap:optimization_mpcc}. In this process, a power-interconnected system was considered; however, since this study focuses on the gas system, the power system remained constant without variation. As in the previous setup, noise was introduced into the base values of two gas networks: a small-scale test network of 8 nodes and the more extensive Colombian natural gas transportation system. The noise levels, ranging from 5\% to 25\%, simulate various operating conditions, providing diverse training data.


\begin{figure}[h]
    \centering
    \setlength\figurewidth{1\textwidth}        
    \setlength\figureheight{0.4\textwidth}
    \resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/model_description.tex}}
    % \input{figures/Chapter_LinealCensnet/MLP_def.tex}
    \caption{General outline of the CensNet-based model used with physics guidance.}
        \label{fig:nonlineal_model_description}
\end{figure}

\section{Results}


In this section, we present the results of the proposed model, which now incorporates physical constraints from the natural gas system. The focus remains on the relationship between the predicted outputs and the actual observed values, evaluating the model's performance across the 8-node test network and the Colombian natural gas transportation system. By incorporating physics-based constraints, the goal is to assess the model's ability to predict critical parameters under various operational conditions while ensuring that the physical laws governing gas flow are respected.

\subsection{Case Study I: 8-node Network}



In this chapter, we begin with experiments that account for both node and edge losses, as it was found that considering only the node loss did not produce adequate results. The best parameters identified for this experiment were $N \ channels=25$, $N \ layers =4$, and $N \ dense = 11$. These settings yielded a total loss of 6.8, with a node loss of 2.8 and an edge loss of 4.02.

The results corresponding to the nodes, shown in \Cref{fig:results_nonlineal_dummy_base_node}, exhibit a similar behavior to that observed in 
\Cref{fig:results_dummy_node_base_f}, demonstrating that the model accurately captures the injection pattern at the nodes. The correlation between the actual and predicted values is also strong, as indicated by an $R^2$ of 0.983.

Edge flows show some variation, as seen in \cref{fig:results_nonlineal_dummy_base_f}, mainly when predicting the flows through the first pipeline connected to the injection field, where slight deviations from the actual flow values were observed in the blue dots. However, the model performed well overall, achieving an $R^2$ of 0.983 for the edge flows. While the first pipeline presents some prediction challenges, the accuracy in predicting flows across the remaining the pipelines remains high, demonstrating the model's ability to handle the complexity of gas transportation in this nonlinear system.


\begin{figure}[h] 
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_base_node}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}


The second part of this experiment involves the additional loss associated with the gas balance, building upon the previous setup that considered both node and edge losses. The hyperparameter optimization yielded the best parameters: $N \ channels =61$, $N \ layers =2$, and $N \ dense=2$. These settings resulted in a total loss of 10.041, with a node loss of 2.9, an edge loss of 6.4, and a balance loss of 0.78.

The prediction behavior at the nodes, as shown in \Cref{fig:results_nonlineal_dummy_node_base_f_bal}, remained consistent with the results obtained in the previous experiment, where the balance loss was not included. The model accurately captured the gas injection pattern, with an $R^2$ of 0.983 for node flow predictions, identical to the earlier case.

Similarly, the prediction of edge flows, shown in \Cref{fig:results_nonlineal_dummy_edge_base_f_bal}, followed the same general trend as before, although a slight decrease in accuracy was observed, reflected by an $R^2$ of 0.973. While this represents a minor reduction in performance compared to the previous experiment, the model still demonstrated a strong ability to predict gas flows through the edges, maintaining a high level of accuracy.

\begin{figure}[h]
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f_bal.tex}}}
    \subfloat[Edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f_bal.tex}}}
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance loss in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}


In the following part of this experiment, we incorporated losses associated with node and edge flows, the gas balance, and the Weymouth equation. The hyperparameter optimization for this setup yielded the following best parameters: $N \ channels=17$, $N \ layers =1$, and $N \ dense =4$. These settings resulted in a total loss of 20.670, with the individual losses being a node loss of 3, an edge loss of 11.35, a balance loss of 2.72, and a Weymouth equation loss of 3.59.

As shown in \Cref{fig:results_nonlineal_dummy_node_base_f_bal_wey}, the behavior of the node flow predictions remained consistent with the previous experiments, with an $R^2$ of 0.983. The model continued to accurately capture the gas injection patterns at the nodes.

However, the prediction accuracy for edge flows showed a notable deterioration, as seen in \Cref{fig:results_nonlineal_dummy_edge_base_f_bal_wey}. The $R^2$ value for edge flow predictions dropped to 0.952. This decrease in performance is primarily due to the difficulties encountered in predicting flows along edges 1, 2, 6, and 7. Edges 1 and 2 correspond to pipelines that are part of a closed path in the network, while edges 6 and 7 correspond to compressors. These complexities in the network configuration likely contributed to the reduction in predictive accuracy for these specific edges.

\begin{figure}[h]
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Actual vs predicted nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_f_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_f_bal_wey.tex}}}
    \subfloat[Actual vs predicted edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_f_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_f_bal_wey.tex}}}
    
    \caption{Model results using the losses associated with nodal and edge flow predictions along with the gas balance and Weymouth losses in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}

In the subsequent experiment, the losses associated with node flows and the physical equations—namely, the gas balance and the Weymouth equation—were considered. The hyperparameter optimization process resulted in the best parameters being $N \ channels=18$, $N \ layers=1$, and $N \ dense=5$. These settings led to a total loss of 10.270, with a node loss of 3.976, a balance loss of 4.75, and a Weymouth equation loss of 1.55. The prediction at the nodes, shown in \Cref{fig:results_nonlineal_dummy_node_base_bal_wey}, remained largely consistent with previous experiments, though there was a slight decrease in accuracy, with the $R^2$ value dropping to 0.976. This minor reduction indicates that the model continues to perform well in predicting gas injection patterns at the nodes. However, the prediction accuracy for edge flows, as seen in \cref{fig:results_nonlineal_dummy_edge_base_bal_wey}, experienced another decline. The $R^2$ value dropped to 0.899, reflecting increased difficulties in predicting flows through the compressors and the pipeline connected to the injection field. 



\begin{figure}
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Actual vs predicted nodal flows.] 
    {\label{fig:results_nonlineal_dummy_node_base_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_bal_wey.tex}}}
    \subfloat[Actual vs predicted edge flows.] 
    {\label{fig:results_nonlineal_dummy_edge_base_bal_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_bal_wey.tex}}}
    
    \caption{Model results using the loss associated with nodal flow predictions along with the gas balance and Weymouth losses in the 8-node network.}
    \label{fig:dummy_base_results}
\end{figure}



% In the final stage of the experiment, only the losses associated with nodal flows and the Weymouth equation were considered. The optimal hyperparameters for this configuration were $ N \ channels=22$, $ N \ layers=1$, and $ N \ dense=19$. These parameters yielded a total loss of 2.798, entirely attributed to the node loss, while the Weymouth loss was effectively zero.
%
% The node predictions, as depicted in \cref{fig:results_nonlineal_dummy_node_base_wey}, continued to perform similarly to most of the previous tests, with an $R^2$ of 0.983, indicating consistent and accurate predictions of gas injection patterns at the nodes.
%
% However, the edge predictions, shown in \cref{fig:results_nonlineal_dummy_edge_base_wey}, were significantly off target in this case. The model struggled to generalize edge flows, resulting in a drastically negative $R^2$ of -2.32, signaling a complete failure in predicting gas flows through the network's edges. 
%
% \begin{figure}
%     \centering
%     \setlength\figurewidth{.53\textwidth}        
%     \setlength\figureheight{0.36\textwidth} 
%     \subfloat[Actual vs predicted nodal flows.] 
%     {\label{fig:results_nonlineal_dummy_node_base_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_dummy_base_wey.tex}}}
%     \subfloat[Actual vs predicted edge flows.] 
%     {\label{fig:results_nonlineal_dummy_edge_base_wey}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_dummy_base_wey.tex}}}
%     
%     \caption{Model results using only the loss associated with nodal flow predictions in the 8-node network.}
%     \label{fig:dummy_base_results}
% \end{figure}
%
%



% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
%     \hline
%     Method & \centering N & \centering E & \centering B & \centering W & Node Value & Edge Value & Balance Value & Time \\ \hline
%     IPOPT  &  &  &  &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} &  &  &  & 4.81 ± 12.64 & 0.42 ± 2.36 & -0.016 ± 17.448 & 0.13 ± 0.03 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  &  & 4.92 ± 13.02 & 22.96 ± 15.36 & 0.095 ± 1.678 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & 4.83 ± 12.65 & 23.20 ± 14.92 & 0.004 ± 0.845 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & 4.76 ± 12.51 & 22.93 ± 14.64 & -0.070 ± 1.665 & 0.14 ± 0.05 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} &  & \makebox[0.55cm]{\centering \checkmark} & 4.88 ± 12.01 & 20.58 ± 12.99 & 0.046 ± 2.187 & 0.13 ± 0.03 \\ \hline
%     % IPOPT  & \makebox[0.55cm]{\centering \checkmark} &  &  & \makebox[0.55cm]{\centering \checkmark} & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} &  &  & \makebox[0.55cm]{\centering \checkmark} & 4.91 ± 12.81 & -0.091 ± 0.185 & 0.079 ± 17.225 & 0.14 ± 0.05 \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, nodal balance, and prediction time between IPOPT and GNN across different loss configurations. The columns "N", "E", "B", and "W" indicate experiments where nodal, edge, balance, and Weymouth losses were considered.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}
%



\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
    \hline
    Method & Node Value & Edge Value & Balance Value & Time \\ \hline
    IPOPT & 4.81 ± 12.81 & 23.18 ± 15.25 & -0.024 ± 0.308 & 0.99 ± 0.53 \\ \hline
    GNN (N) & 4.81 ± 12.64 & 0.42 ± 2.36 & -0.016 ± 17.448 & 0.13 ± 0.03 \\ \hline
    GNN (N+E) & 4.92 ± 13.02 & 22.96 ± 15.36 & 0.095 ± 1.678 & 0.14 ± 0.05 \\ \hline
    GNN (N+E+B) & 4.83 ± 12.65 & 23.20 ± 14.92 & 0.004 ± 0.845 & 0.14 ± 0.05 \\ \hline
    GNN (N+E+B+W) & 4.76 ± 12.51 & 22.93 ± 14.64 & -0.070 ± 1.665 & 0.14 ± 0.05 \\ \hline
    GNN (N+E+W) & 4.88 ± 12.01 & 20.58 ± 12.99 & 0.046 ± 2.187 & 0.13 ± 0.03 \\ \hline
\end{tabular}
\caption{Comparison of the mean and standard deviation values for nodal flows (Node Value), edge flows (Edge Value), nodal balance (Balance Value), and prediction time (Time) between the optimization-based method (IPOPT) and the GNN-based models under different loss configurations. The notation \textbf{GNN (N)} indicates that only the nodal loss was considered during training, while \textbf{GNN (N+E)}, \textbf{GNN (N+E+B)}, and so on indicate combinations of nodal (N), edge (E), balance (B), and Weymouth (W) losses.}
\label{tab:base_nl_dummy_results_simplified}
\end{table}



The results in \Cref{tab:base_nl_dummy_results_simplified} compare the performance of the traditional IPOPT optimizer and several Graph Neural Network (GNN) configurations trained with different combinations of loss functions. The evaluation focuses on nodal and edge flow prediction accuracy, network balance, and computation time.

As a baseline, the IPOPT optimizer yields consistent results across all evaluated metrics, offering a reference for model performance. In contrast, the GNN-based approaches reveal how incorporating physical constraints progressively improves the model's predictive accuracy. When trained with only the nodal loss, the GNN matches the optimizer's performance in predicting nodal flows but performs poorly in edge flow estimation and maintaining nodal balance. This result reflects the absence of edge- and balance-specific information during training, which is essential for reproducing physically consistent flows in the network.

Adding edge loss to the training objective enhances the GNN’s ability to predict edge flows, bringing them in line with the optimizer’s outputs. This improvement comes with reduced variability in the nodal balance, indicating that learning edge-specific relationships also reinforces overall network consistency. The introduction of the balance loss further stabilizes the model’s performance. With this additional constraint, the GNN reduces balance error variability and further aligns both nodal and edge flow predictions with the benchmark.

Finally, incorporating the Weymouth equation into the loss function introduces the non-linear physics of gas transport into the learning process. Although this results in a modest reduction in balance accuracy compared to the previous configuration, it still maintains high predictive performance for nodal and edge flows. Notably, despite the increasing complexity introduced by each added constraint, all GNN models maintain a low and consistent prediction time—markedly faster than the optimization-based method—demonstrating the GNN’s scalability and computational efficiency.


\subsubsection{Stochastic Analysis}

To study the uncertainty inherent in the network further, we first approximated the joint probability density functions (PDFs) for the variables used as inputs to the network. For training, each node was assigned five inputs, corresponding to the lower limit of gas injection capacity, the upper limit of gas injection capacity, the demanded flow, the lower limit of pressure, and the upper limit of pressure. Since the lower limits are permanently fixed at zero, these two variables were excluded from the analysis. Although the training data were initially sampled from a uniform distribution, only the successfully converged samples during the optimization process were retained. Consequently, the resulting PDFs do not exhibit a uniform distribution; instead, they display a variety of distribution shapes.

\Cref{fig:joint_distributions_input_input} presents the first group of joint distributions identified in this study, characterized by the presence of two distinct modes, which likely correspond to the two main operating regimes of the system. This group includes joint patterns involving the injection node ($N_0$), the demand nodes ($N_6$ and $N_7$), and several intermediate or pass-through nodes ($N_2$, $N_4$, and $N_5$). The observed relationships reflect the physical and topological structure of the network, particularly the connections among injection, compression, and demand points.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.8\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs.png}
    \end{center}
    \caption{Joint PDFs between the inputs used in the 8-node network, which have two modes. }\label{fig:joint_distributions_input_input}
\end{figure}
 
A relationship is observed between the upper-pressure limits at nodes \( N_2 \) and \( N_4 \), which aligns with their placement within a sequential compression segment of the network. Node \( N_2 \) serves as the output of the first compressor and the input to the second, while node \( N_4 \) lies on a closed-loop path downstream of this compression chain. The correlation between their pressure bounds likely reflects how the viable operating range at one point in the compression sequence affects neighboring nodes within the loop. Similarly, the pressure limit correlation between node \( N_5 \), also part of the closed path, and the downstream demand node \( N_6 \), suggests that feasible pressure ranges propagate along connected elements of the network, especially where compression and demand interact.


A subgroup of distributions reveals strong associations between the maximum demand at node $N_7$ ($\overline{f_u}$) and upstream variables. Specifically, $N_7$'s maximum flow shows dependence on the maximum injection flow at node $N_0$ ($\overline{f_w}$), and on the maximum pressures at nodes $N0$, $N1$ (compressor 1 input), and $N5$. These patterns suggest that the flow capacity at the far end of the system ($N_7$) is conditioned by both supply and compression states at the upstream nodes. Also, a direct relationship is identified between the pressure limits of node $N_7$ and node $N_4$. Given their physical connection, this correlation likely reflects the way pressure constraints propagate between adjacent sections of the network.

    

\Cref{fig:joint_distributions_input_input_no_mode} presents a second group of joint distributions identified in the study, which are characterized by low probability concentrations at their extreme values. This behavior, visually represented by lighter colors in the joint probability density functions, suggests a weaker or more dispersed correlation structure between the involved variables.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.8\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_no_mode.png}
    \end{center}
    \caption{Joint PDFs between the inputs used in the 8-node network, which do not appear to have a defined mode. }
    \label{fig:joint_distributions_input_input_no_mode}
\end{figure}


Several of these relationships involve the injection node $N_0$ and its connection to both upstream and downstream nodes in terms of maximum pressure ($\overline{\pi}$) and maximum injection flow ($\overline{f_w}$). For instance, the joint distributions between the maximum pressure at $N2$ and $N_0$, as well as between the maximum pressures at $N_3$, $N_4$, and $N_6$ with that of $N_0$, reveal a broadly scattered pattern. This indicates that while these variables are structurally related, their extreme values do not consistently co-occur. A similar pattern is observed in the distributions involving the maximum pressure at $N_3$ and the injection capacity at $N_0$. Despite the proximity of these nodes within the system’s trajectory, the weak concentration suggests a more flexible operational regime or buffering effect along the path.

Further examples include the relationships between $N_5$ and both $N_0$ and $N_2$, where again, the lack of sharp density at the extremes hints at variability in how pressure is maintained or transmitted through these nodes. Lastly, the distributions between the maximum pressure at $N_6$ and both $N_0$ and $N_3$ continue this trend, reinforcing the understanding that, in these cases, the system does not exhibit a strong link in the upper operational ranges of the involved variables.




\Cref{fig:joint_distributions_input_input_wide_mode} presents a third group of joint distributions distinguished by the presence of large dark zones in the joint probability density functions, indicating regions of high probability concentration. These distributions suggest strong dependencies between the involved variables. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.8\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_wide_mode.png}
    \caption{Joint PDFs between the inputs used in the 8-node network, which have a considerably wide mode with respect to the entire distribution.}
    \label{fig:joint_distributions_input_input_wide_mode}
\end{figure}


A clear example is the distribution involving the maximum injection flow at node $N_0$ and the maximum pressure at node $N_1$, which corresponds to the input of the first compressor. The high-probability region observed here suggests a consistent relationship between the capacity to inject gas into the network and the pressure conditions at the compressor’s intake, possibly reflecting operational constraints or control strategies that maintain a stable relationship between these variables.

Likewise, the joint distribution between the maximum pressure at node $N_1$ and the pressure at node $N_4$ (a pass-through node connected downstream) also shows a dense concentration of probability. This implies a strong coupling between the input conditions of the first compressor and the downstream pressure, likely due to the system’s physical configuration and flow continuity.

Lastly, a similar pattern is observed in the joint distribution between the maximum demand at node $N_6$ and the pressure at node $N_4$. The high-probability zone here may indicate a regulatory relationship, where variations in demand at $N_6$ are closely associated with pressure conditions at $N_4$, possibly due to their direct physical connection and the influence of demand on local pressure levels.
 



To continue with the stochastic analysis, here we discuss the joint probability density functions (PDFs) that exhibit noteworthy behaviors, obtained from the output variables of the optimization model when it was supplied with the various scenarios generated through the previously described sampling process. It is important to note that, at this stage, each output variable was normalized with respect to the maximum capacity used in the corresponding scenario. That is, the values of the variables shown in this section are expressed relative to the maximum value that the variable could reach under that specific configuration.



\Cref{fig:joint_distributions_output_output_1} presents the joint distributions that exhibit a bivariate gamma distribution-like shape. In this case, the X-axis corresponds to the normalized flow transported through pipeline $p_1$, which connects nodes $N_3$ and $N_4$ and forms part of the system’s closed-loop trajectory. The Y-axis in each of the four subplots represents the normalized nodal pressure at nodes $N_3$, $N_4$, $N_6$, and $N_7$, respectively.

Nodes $N_3$ and $N_4$ are part of a compact subsystem of pass-through nodes that define the core loop of the network. $N_6$ and $N_7$, while functioning as demand nodes, are connected downstream of this region, with $N_7$ specifically being supplied via node $N_4$. This spatial arrangement suggests that the observed distributions highlight the interdependence between the transported flow through this central pipeline and the pressure conditions at nearby or downstream nodes. In particular, although $N_6$ is slightly more distant, its role as a demand node may explain its inclusion in this group of correlated behaviors.


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.75\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_1.png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network have a behavior quite similar to that of a bivariate gamma distribution.}
    \label{fig:joint_distributions_output_output_1}
\end{figure}




\Cref{fig:joint_distributions_output_output_2} presents another group of joint probability density functions with a similar behavior to the previous case. However, a difference in this case is that the X-axis in all subplots takes on negative values, ranging between 10\% and 30\% of the maximum limit. The variable associated with this axis in all the figures corresponds to the normalized flow transported through pipeline $p_3$, which is the component responsible for closing the loop in the system’s network structure. The variables plotted along the Y-axis correspond to various system outputs, including the normalized gas injection flow from the injection field, the nodal pressures at every node in the system and and the flow transported by each pipeline.

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_2.png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network, which have a negative flow.}
    \label{fig:joint_distributions_output_output_2}
\end{figure}


The consistent behavior observed across these joint PDFs can be interpreted through two main considerations. First, although pipeline $p_3$ is not essential for guaranteeing the operability of the system, it plays a key role in minimizing operational costs. As a result, its usage remains relatively low across most scenarios. Second, the negative values of the flow are due to the fact that, during the formulation of the optimization model, the assumed flow direction for this pipeline was opposite to the one actually needed to satisfy the optimal operation. Consequently, the model resolved this mismatch by assigning negative values to the transported flow in $p_3$.




\Cref{fig:joint_distributions_output_output_3} displays a third group of joint probability density functions that exhibit another pattern. In these distributions, both variables tend to take values within a range—approximately between 25\% and 70\% of their respective maximum capacities. Despite this wide span, the distributions do not resemble uniform patterns. Instead, they appear to exhibit a clear concentration of higher probability in a more restricted interval, specifically when both variables fall between 30\% and 40\% of their normalized limits.

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_3.png}
    \end{center}
    \caption{Joint probability density functions (PDFs) between nodal pressure outputs in the 8-node network, highlighting a concentration of values within mid-range operating levels (30\%–40\% of normalized limits)}
    \label{fig:joint_distributions_output_output_3}
\end{figure}
 

This behavior is particularly evident in the joint PDFs that relate nodal pressures across different yet structurally connected regions of the system. One set of these distributions involves the pressure at the injection node ($N_0$) and the pressures observed at downstream nodes, including the compressor-connected nodes ($N_1$, $N_2$, and $N_3$), as well as the nodes forming the closed loop ($N_3$, $N_4$, and $N_5$) and the final demand nodes ($N_6$ and $N_7$). These distributions suggest a degree of coordination in the pressure values that extends from the injection point through the compression stages and into the rest of the system.

The tendency of these variables to cluster within a narrower operational range may indicate that the system's feasible configurations favor pressure levels that are not too close to the lower or upper bounds, but rather stabilized in a middle region that ensures both efficiency and reliability. This is especially relevant in subsystems like the closed-loop segment formed by nodes $N_3$, $N_4$, and $N_5$, which play a critical role in redistributing flow toward the demand points. The same applies to the pressures at the terminal load nodes ($N_6$ and $N_7$), which depend on adequate upstream conditions to meet demand.








% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_linear.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which have a quite marked linear behavior.}\label{fig:joint_distributions_output_output_linear}
% \end{figure}
%  
%
% Figure~\ref{fig:joint_distributions_output_output_linear} illustrates a group of joint distributions exhibiting a markedly linear behavior, almost as straight lines with a clear slope. These distributions capture the relationships between the pressures at a given node and those at downstream nodes, starting with node N4, which is positioned at the outlet of the compressors. This linear trend is expected because, in order to maintain unidirectional gas flow, the pressures throughout the network must decrease gradually. 
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_5.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which have a Gaussian behavior with small covariances }\label{fig:joint_distributions_output_output_5}
% \end{figure}
%  
%
% Another group of joint distributions, which can be seen in Figure~\cref{fig:joint_distributions_output_output_5}, was observed to resemble a normal distribution closely but with much lower dispersion, indicating smaller covariances among the variables. These distributions were obtained by correlating the flow through the first pipeline with the pressures measured at all nodes in the network. Similar patterns are also observed when the nodal pressures are compared with the flows through edges E6 and E7; however, these images are omitted because the three edges are connected sequentially and share the same gas flow, their behavior is as expected.
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.67\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_6.png}
%     \end{center}
%     \caption{Joint PDFs among the outputs used in the 8-node network, which are quite dispersed along the variable associated with the N7 node flow.}\label{fig:joint_distributions_output_output_6}
% \end{figure}
%  
%
% Figure~\cref{fig:joint_distributions_output_output_6} shows the group characterized by distributions that are elongated along the axis of the first variable used in constructing the joint PDF while exhibiting a narrower spread along the second variable's axis. In our study, this subgroup includes the distributions that relate the gas flow on edge E4—which carries gas to the N7 demand node—to the pressures measured at each node. This behavior suggests that variations in the gas flow on E4 are more strongly influenced by the pressure variable, resulting in a pronounced elongation in that direction. 
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_7.png}
%     \end{center}
%     \caption{Joint PDFs between the outputs used in the 8-node network, which show a negative linear behavior. }\label{fig:joint_distributions_output_output_7}
% \end{figure}
%  
%
% A final group of joint distributions can be seen in Figure~\cref{fig:joint_distributions_output_output_7}. This group is characterized by distributions with an inversely proportional behavior. The joint PDFs in this group are associated with the relationship between the flow transported by edge E3 and the flows transported by the other edges, except those corresponding to edges E4 and E5. This result is interesting, as it reflects a distinct behavior of the system: edges E1, E2, and E3 form a closed trajectory, and according to the initially assumed flow direction, there were instances in which edge E3 exhibited a flow opposite to that expected. In contrast, the flows that do not display this inverse relationship leave the closed trajectory to feed the demand nodes.
%
%
% The relationships between input and output variables were further analyzed to conclude the study of the joint distributions obtained from the variables in this case study. As in previous analyses, several groups of distributions with similar behavior were visually identified. 
%
%

It is also relevant to examine the joint probability distributions between input and output variables (\Cref{fig:joint_distributions_inputs_outputs_1}), particularly those in which the input variables exhibit significantly broader dispersion compared to the outputs. This behavior can be observed in a group of joint PDFs where the outputs—specifically, the flow through pipeline $p_4$—tend to remain concentrated within the 20\% to 40\% range of their normalized capacities, while the corresponding input variables vary much more widely. It is important to highlight that, in this case, normalization was only applied to the output variables. The inputs, being defined as upper bounds or operational limits (such as the maximum allowable injection flow or pressure limits), were not normalized. 

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.65\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_1.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a wide dispersion along second variable. }
    \label{fig:joint_distributions_inputs_outputs_1}
\end{figure}


The most illustrative examples of this pattern involve joint distributions between the upper bound of the injection flow at node $N_0$ and the flow in $p_4$, as well as between the upper nodal pressure bounds at nodes $N_0$ through $N_7$ and the same pipeline output. Pipeline $p_4$ corresponds to the final segment delivering gas to one of the system’s demand nodes. The limited range of variation in this output, despite the broad dispersion in input conditions, suggests that the optimizer consistently resolves the system by prioritizing stable and relatively low utilization of this pipeline. 



Another remarkable group of joint PDFs arises from the relationship between input and output variables that exhibit a seemingly linear behavior, shows in \Cref{fig:joint_distributions_inputs_outputs_2}. In these distributions, an increase in the input variable tends to be associated with an increase in the output variable, suggesting a positive correlation. This pattern is especially evident in the pairs formed by the upper bound of the demand flow at nodes $N_6$ and $N_7$, and the flow transported through pipelines $p_4$, $p_5$, $p_6$, and $p_7$. These pipelines are directly or indirectly responsible for supplying gas to the demand nodes, meaning that as the upper flow limits at the consumption points increase, the optimizer adjusts the flows along these pipelines accordingly, typically utilizing a larger fraction of their capacity. 

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_2.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a linear behavior, although with different dispersions among them. }\label{fig:joint_distributions_inputs_outputs_2}
\end{figure}
 
However, it is important to note an exception within this group: the pair formed by the upper flow bound at node $N_7$ and the flow through pipeline $p_3$ presents a negative linear relationship. In this case, an increase in the upper demand limit at $N_7$ is associated with a decrease in the use of pipeline $p_3$. This inverse behavior can be explained by the system's looped configuration, where $p_3$ contributes to a closed trajectory. Under higher demand at $N_7$, the optimizer might favor alternative paths that more directly satisfy the load, such as pipelines $p_5$ through $p_7$, reducing the role of $p_3$ in transporting gas.



A stochastic analysis was performed to assess further the robustness of the trained GNN-based model and its ability to generalize under uncertainty. This analysis is motivated by the need to simulate and evaluate the model's responses in scenarios that were not explicitly present in the training data, thereby providing a means to quantify the variability and reliability of the model's predictions.

Initially, a kernel density estimate (KDE) was fitted to the input training data used for the GNN model. From this estimated distribution, a set of synthetic input samples, denoted as \( X_{\text{sample}} \), was generated. These synthetic inputs were then propagated forward through the trained network, taking into account all loss components, to yield a corresponding set of output predictions, denoted as \( y_{\text{sample}} \). In parallel, the original training inputs were propagated through the network to obtain output predictions, denoted as \(\bar{y}_{\text{train}}\). A second KDE was then fitted using the training output data (hereafter referred to as \(y_{\text{train}}\)). Two log-likelihoods were calculated based on this second KDE: one using \(y_{\text{sample}}\) and the other using \(\bar{y}_{\text{train}}\). The log-likelihood for the synthetic outputs, \(y_{\text{sample}}\), was found to be \(-6,696,247.56\), while the log-likelihood for the training outputs, \(\bar{y}_{\text{train}}\), was \(-6,657,534.62\). The closeness of these two values suggests that the synthetic outputs generated from the input KDE closely resemble the distribution of the training outputs.

To further evaluate the goodness-of-fit between the distributions of \( y_{\text{sample}} \) and \( \bar{y}_{\text{train}} \), a Kolmogorov–Smirnov (K–S) test was conducted using three alternatives: two-sided, less, and more significant. The test results were as follows: a two-sided test yielded a statistic of \( 0.01833 \) with a p-value of \( 0.81482 \) (statistic location \(-0.34018\); the 'less' alternative produced a statistic of \( 0.01167 \) with a p-value of \( 0.72137 \) (statistic location \(0.30738\); and the 'greater' alternative returned a statistic of \( 0.01833 \) with a p-value of \( 0.44640 \) (statistic location \(-0.34018\). These statistical measures provide an initial indication that the synthetic outputs generated via the KDE-based sampling are consistent with the distribution of outputs observed during training, thereby supporting the model's capability to generalize to new, unseen scenarios.




After completing the stochastic analysis of the variables associated with the optimization model—both input and output variables—the next step involves leveraging the KDE fitted to the training data. This fitted KDE was used to generate a new set of input samples that represent the learned probability distribution of the optimization model's inputs. These samples were then propagated forward through the trained neural network model. Using the resulting network outputs, a new joint analysis was conducted, analogous to the previous one performed with the variables of the optimization model. This approach allows for evaluating the network's ability to reproduce the statistical behavior of the system, offering an understanding of how the learned model captures the underlying probabilistic structure of the original problem.



\begin{figure}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs (Sampled).png}
    \end{center}
    \caption{Joint PDFs between the entries used in the 8-node network, which have two modes in the KDE sampled variables}
    \label{fig:joint_distributions_input_input_KDE}
\end{figure}
     

Following the same structure presented in the first part of this analysis, we begin by highlighting the relationships that exhibit two distinct modes of operation according to their joint probability density functions. In this case, as shown in Figure~\cref{fig:joint_distributions_input_input_KDE}, only two variable pairs present this bimodal behavior when the analysis is performed using the inputs propagated through the trained neural network. These pairs are: the nodal pressure limits of $N_4$ and $N_2$, and those of $N_6$ and $N_5$. In both cases, the joint PDFs suggest the existence of two operational regimes, potentially associated with alternative configurations or routing strategies within the network that are learned by the neural model. 


\begin{figure}
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/PDF_inputs_inputs_no_mode (KDE).png}
    \end{center}
    \caption{Joint PDFs between the inputs used in the 8-node network, which do not appear to have a defined mode in the KDE sampled variables. }
    \label{fig:joint_distributions_input_input_no_mode_KDE}
\end{figure}
 
Continuing with the distributions that exhibit a very small high-probability region, four pairs of variables were identified in this case whose joint PDFs display this characteristic. These pairs are: the nodal pressure limits between $N_2$ and $N_0$; between $N_3$ and $N_0$ for both pressure and injected flow limit; and between $N_5$ and $N_2$ for nodal pressures. These distributions are characterized by a concentrated and sharply defined region of high probability, suggesting that the neural network tends to favor very specific combinations of input values during prediction. It is worth noting that, unlike in the previous analysis based on the optimization model, no distributions with broad and clearly defined high-probability zones (i.e., darker and more extensive areas) were observed.


\begin{figure}
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/outputs_outputs_2 (KDE).png}
    \end{center}
    \caption{Joint PDFs between the outputs used in the 8-node network, which have a negative flow in the KDE sampled variables.}
    \label{fig:joint_distributions_output_output_2_KDE}
\end{figure}
 

Figure~\ref{fig:joint_distributions_output_output_2_KDE} presents a group of joint probability density functions that, while resembling Gaussian-like distributions, often exhibit some degree of skewness. A particularly striking feature in these plots is the consistent behavior of the flow transported through pipeline $E_3$, the segment that completes the loop in the system’s topology. In every case, this variable—represented on the X-axis—takes on negative values, typically between 10\% and 30\% of its normalized capacity.

This consistent negative trend can be interpreted as the network having learned that, under optimal conditions, the flow through pipeline $E_3$ should operate in the direction opposite to the one originally assumed in the problem formulation. The reversal in direction is not only coherent with the physical and economic constraints of the system, but also mirrors the behavior found in the optimization model. Furthermore, this pattern is robust across a diverse set of operating scenarios, as evidenced by the variables plotted along the Y-axis, which include the total injection at node $N_0$ and the flows through pipelines $E_0$, $E_1$, $E_2$, $E_4$, and $E_5$. 


\begin{figure}
    \begin{center}
        \includegraphics[width=.65\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_1 KDE.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a wide dispersion along second variable. }
    \label{fig:joint_distributions_inputs_outputs_1_KDE}
\end{figure}

Continuing with the comparison between input and output variables, a similar pattern to that observed in the optimization model reappears in the neural network predictions. As shown in Figure~\cref{fig:joint_distributions_inputs_outputs_1_KDE}, there is a group of joint probability distributions where the input variables span a wide range of values, while the corresponding output—specifically, the flow through pipeline $E_4$—remains narrowly concentrated between 20\% and 40\% of its normalized capacity. This behavior mirrors what was previously discussed for the optimization model, suggesting that, even under the learned data distribution, the network consistently predicts a relatively low and stable utilization of this particular pipeline.

The pairs exhibiting this characteristic include the upper bound on injection flow at node $N_0$ and the upper bounds on nodal pressures at nodes $N_0$ through $N_7$, all compared against the predicted flow through pipeline $E_4$. As in the previous case, normalization was only applied to the output variables, while the inputs were left in their original scale, reflecting their interpretation as operational constraints rather than actual realizations. The similarity in joint distribution patterns between the optimization model and the neural network predictions indicates that the trained model effectively internalized a similar resolution strategy, favoring stable usage of pipeline $E_4$ regardless of the variability in input conditions.


\begin{figure}
    \begin{center}
        \includegraphics[width=.7\textwidth]{figures/Chapter_NonLinealCensnet/inputs_outputs_2 KDE.png}
    \end{center}
    \caption{Joint PDFs between the inputs and outputs used in the 8-node network, which present a linear behavior, although with different dispersions among them. }
    \label{fig:joint_distributions_inputs_outputs_2_KDE}
\end{figure}
 

A final group of joint distributions worth highlighting involves input and output variables that exhibit a linear relationship, similar to the patterns observed in the optimization model (Figure~\cref{fig:joint_distributions_inputs_outputs_2_KDE}). In particular, two of the joint PDFs show a positive correlation, where increases in the input variable are associated with proportional increases in the output. This behavior is seen in the pairs formed by the upper bound of the demand flow at node $N_6$ and the predicted flow in pipeline $E_4$, as well as between the same bound at node $N_7$ and the predicted flow in pipeline $E_5$. These relationships suggest that the network has captured a coherent system response, in which more flexible demand conditions at the consumption nodes lead to higher utilization of the pipelines supplying them—closely resembling the optimizer’s behavior.

A third pair—formed by the upper demand bound at node $N_7$ and the flow in pipeline $E_3$—also shows a strong linear pattern, though in this case the correlation is negative. That is, an increase in the input variable corresponds to a decrease in the pipeline’s predicted utilization. This result mirrors the exception found in the optimization model, and can again be attributed to the presence of a loop in the network’s structure. Under increasing demand at $N_7$, the network tends to shift the flow away from pipeline $E_3$, likely in favor of more direct paths that connect to the demand node. This further confirms that the trained model not only replicates the general operating tendencies of the optimization scheme but also reflects more subtle topological effects embedded in the system configuration.
















\subsection{Case Study II: 63-node Network (Colombia)}


This section addresses the second case study, focusing on the Colombian natural gas network. As in the previous cases, this analysis explores various configurations of loss functionals to evaluate the predictive performance of the GNN-based model. The first experiment examines the model's predictive capabilities when incorporating node and edge losses.


This experiment used optimized hyperparameters, with \( N_{\text{channels}} = 21 \), \( N_{\text{layers}} = 5 \), and \( N_{\text{dense}} = 4 \), which were selected to enhance the model's performance. The experiment yielded a total loss of \( 267,600 \), encompassing node and edge losses, along with a calculated balance loss. Specifically, the node loss reached \( 17,537 \), while the edge loss was considerably higher at \( 250,063 \). Additionally, a balance loss of \( 338,729 \) was recorded. Notably, the balance loss was calculated to assess network consistency but was not incorporated into the model's cost function during training; instead, it serves as an independent evaluation metric. 

The GNN-based model's predictive accuracy in this experiment was quantified using \( R^2 \) metrics, and the results are shown in \cref{fig:col_base_f_results_non_lineal}. The nodal predictions exhibited high accuracy, with an \( R^2 \) score of \( 0.993 \) in \cref{fig:results_nonlineal_col_node_base_f}, indicating that the model closely approximates the observed nodal flow values. Similarly, the edge predictions achieved an \( R^2 \) score of \( 0.963 \), demonstrating robust performance in predicting edge flows. This last value can be seen in \cref{fig:results_nonlineal_col_edge_base_f}.


\begin{figure}
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Actual vs predicted nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_f.tex}}}
    \subfloat[Actual vs predicted edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_f}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_f.tex}}}
    
    \caption{Model results using only the loss associated with nodal flow predictions in the 8-node network.}
    \label{fig:col_base_f_results_non_lineal}
\end{figure}


The second experiment evaluated the GNN-based model, focusing on losses associated with nodes and balance. Using the optimized hyperparameters \( N_{\text{channels}} = 49 \), \( N_{\text{layers}} = 5 \), and \( N_{\text{dense}} = 2 \), the model yielded a total loss of \( 24,888 \). This loss value includes a node loss of \( 17,019 \), a calculated edge loss of \( 2,912.201 \), and a balance loss of \( 7,868 \). In this experiment, only the node and balance losses were included in the model's cost function, while the edge loss was computed independently to assess prediction accuracy for edge flows.

The predictive accuracy, evaluated using \( R^2 \) metrics, yielded \( R^2 = 0.993 \) for nodal predictions and \( R^2 = 0.569 \) for edge predictions, as shown in \cref{fig:results_nonlineal_col_node_base_bal} and \cref{fig:results_nonlineal_col_edge_base_bal}. The scatterplot in \cref{fig:results_nonlineal_col_node_base_bal} illustrates the accuracy of nodal predictions, with predicted values aligning closely to the true values. In contrast, the scatterplot in \cref{fig:results_nonlineal_col_edge_base_bal} reveals less consistency in edge predictions, likely due to the exclusion of edge loss from the cost function. Although a general linear trend is observable between predicted and true values in this scatterplot, a notable number of inaccurately predicted values diminish the overall \( R^2 \), impacting the edge loss and prediction accuracy.




\begin{figure}
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Actual vs predicted nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_bal.tex}}}
    \subfloat[Actual vs predicted edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_bal.tex}}}
    
    \caption{Model results using only the loss associated with nodal flow predictions in the 8-node network.}
    \label{fig:col_base_bal_results_non_lineal}
\end{figure}




The third experiment evaluated the GNN-based model's predictive capabilities by incorporating losses associated with nodes, edges, and balance. With the optimized hyperparameters \( N_{\text{channels}} = 20 \), \( N_{\text{layers}} = 5 \), and \( N_{\text{dense}} = 2 \), the model achieved a total loss of \( 347,647 \), including a node loss of \( 37,684 \), an edge loss of \( 264,187 \), and a balance loss of \( 45,776 \). This experiment integrated all three losses into the model's cost function, allowing a more comprehensive assessment of its predictive performance.

The predictive accuracy was quantified by \( R^2 \) values of \( 0.984 \) and \( 0.961 \) for nodes and edges, respectively, as shown in \cref{fig:results_nonlineal_col_node_base_f_bal} and \cref{fig:results_nonlineal_col_edge_base_f_bal}. In these scatterplots, the predictions demonstrate a clearer alignment with the true values, with both graphs illustrating shapes more similar to straight lines, which indicates improved model performance in capturing the underlying patterns of nodal and edge flows.

This third experiment marks the final test conducted in this study. Attempts to include the Weymouth loss were hindered by significant computational complexity, preventing the acquisition of reliable results for the model when considering the Weymouth function loss. Therefore, further tests were not feasible within the current scope.

\begin{figure}
    \centering
    \setlength\figurewidth{.53\textwidth}        
    \setlength\figureheight{0.36\textwidth} 
    \subfloat[Actual vs predicted nodal flows.] 
    {\label{fig:results_nonlineal_col_node_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/yn_col_base_f_bal.tex}}}
    \subfloat[Actual vs predicted edge flows.] 
    {\label{fig:results_nonlineal_col_edge_base_f_bal}\resizebox{\figurewidth}{\figureheight}{\input{figures/Chapter_NonLinealCensnet/ye_col_base_f_bal.tex}}}
    
    \caption{Model results using only the loss associated with nodal flow predictions in the 8-node network.}
    \label{fig:col_base_f_bal_results_non_lineal}
\end{figure}



% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
%     \hline
%     Method & \centering N & \centering E & \centering B & \centering W & Node Value & Edge Value & Balance Value & Time \\ \hline
%     \textbf{Base} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & & & & \( 11.22 \pm 49.03 \) & \( 62.73 \pm 81.99 \) & \( -2.28 \pm 25.48 \) &  \\ \hline
%     \textbf{Base bal} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & & \( 12.47 \pm 48.90 \) & \( 88.32 \pm 73.55 \) & \( -1.03 \pm 1.90 \) &  \\ \hline
%     \textbf{Base f Bal} & & & & & & & & \\ 
%     IPOPT  & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) &  \\ \hline
%     GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 12.33 \pm 48.64 \) & \( 63.06 \pm 81.32 \) & \( -1.17 \pm 7.38 \) &  \\ \hline
% \end{tabular}
% \caption{Comparison of mean and standard deviation values for nodal flows, edge flows, and nodal balance between IPOPT and GNN across different loss configurations. The columns "N", "E", and "B" indicate experiments where nodal, edge, and balance losses were considered.}
% \label{tab:base_nl_dummy_results_formatted}
% \end{table}
%


\begin{table}[htbp]
\centering
\begin{tabular}{|c|p{0.55cm}|p{0.55cm}|p{0.55cm}|c|c|c|c|}
    \hline
    Method & \centering N & \centering E & \centering B & Node Value & Edge Value & Balance Value & Time \\ \hline
    IPOPT  & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.32 \pm 48.89 \) & \( 63.38 \pm 83.11 \) & \( -2.18 \pm 29.78 \) & \( 13.65 \pm 2.86 \) \\ \hline
    GNN    & \makebox[0.55cm]{\centering \checkmark} & & & \( 11.22 \pm 49.03 \) & \( 62.73 \pm 81.99 \) & \( -2.28 \pm 25.48 \) & \( 0.15 \pm 0.04 \) \\ \hline
    GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & & \( 12.47 \pm 48.89 \) & \( 88.32 \pm 73.55 \) & \( -1.03 \pm 1.90 \) & \( 0.15 \pm 0.05 \) \\ \hline
    GNN    & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \makebox[0.55cm]{\centering \checkmark} & \( 12.33 \pm 48.64 \) & \( 63.06 \pm 81.32 \) & \( -1.17 \pm 7.38 \) & \( 0.15 \pm 0.04 \) \\ \hline
\end{tabular}
\caption{Comparison of mean and standard deviation values for nodal flows, edge flows, nodal balance, and prediction time between IPOPT and GNN across different loss configurations. The columns "N", "E", and "B" indicate experiments where nodal, edge, and balance losses were considered.}
\label{tab:base_nl_dummy_results_formatted}
\end{table}


The \cref{tab:base_nl_dummy_results_formatted} provides a comparison between the IPOPT optimization model and the GNN-based model across four experiments that incorporate different combinations of nodal (N), edge (E), and balance (B) losses. The results focus on nodal flows, edge flows, nodal balance, and prediction time, with mean and standard deviation values.

In this table, the IPOPT model serves as the baseline. It achieves a nodal flow mean of \( 11.32 \pm 48.89 \), an edge flow mean of \( 63.38 \pm 83.11 \), and a balance value mean of \( -2.18 \pm 29.78 \). The prediction time for this benchmark model is \( 13.65 \pm 2.86 \) seconds, providing a standard for comparison with GNN-based models.

The first GNN experiment considers only the nodal loss. It produces a nodal flow mean of \( 11.22 \pm 49.03 \), closely aligning with the IPOPT nodal flow. The edge flow mean, at \( 62.73 \pm 81.99 \), is also similar to IPOPT's results. The balance value mean of \( -2.28 \pm 25.48 \) shows moderate variability, while the GNN's prediction time is notably faster, at \( 0.15 \pm 0.04 \) seconds.

In the second GNN experiment, both nodal and edge losses are incorporated. The nodal flow prediction mean slightly increases to \( 12.47 \pm 48.89 \), while the edge flow mean shows a more significant increase, reaching \( 88.32 \pm 73.55 \). The balance value improves in consistency, with a mean of \( -1.03 \pm 1.90 \), and the prediction time remains low at \( 0.15 \pm 0.05 \) seconds, indicating efficient computation.

The third GNN experiment includes nodal, edge, and balance losses. Here, the nodal flow means it is \( 12.33 \pm 48.64 \), and the edge flow means returns to a closer alignment with IPOPT at \( 63.06 \pm 81.32 \). The balance value stabilizes, reaching \( -1.17 \pm 7.38 \), while the prediction time remains consistent at \( 0.15 \pm 0.04 \) seconds.

This table illustrates the GNN model's capability to maintain accurate predictions and achieve lower computational time than IPOPT, especially when incorporating more loss components.




An uncertainty analysis similar to the previous case was performed for the Colombian natural gas transportation network. Using the same methodology, a second kernel density estimate (KDE) was fitted to the training output data, and synthetic outputs were generated. The log-likelihood computed from the synthetic outputs was \(-104,413,419.34\), while that computed from the training outputs was \(-104,037,047.58\). In addition, a Kolmogorov–Smirnov (K–S) test was carried out under three different alternatives, yielding the following results: a test statistic of \(0.00527\) with a p-value of \(0.95556\) (statistic location \(0.52109\), statistic sign \(-1\)); a test statistic of \(0.00527\) with a p-value of \(0.59061\) (statistic location \(0.52109\), statistic sign \(-1\)); and a test statistic of \(0.00324\) with a p-value of \(0.81777\) (statistic location \(-0.73443\), statistic sign \(1\)). These findings indicate a high similarity between the synthetic and training outputs, as the low test statistics and high p-values suggest that the two distributions are statistically indistinguishable. The slight differences in log-likelihood values further confirm that the synthetic data effectively capture the essential characteristics of the training data, thereby validating the robustness of the stochastic sampling approach for this network.







\section{Discussion and conclusions}


This chapter's first set of experiments provides insights into the model's capability to handle gas network predictions with various loss function combinations. Including node and edge losses in the initial experiment demonstrated the model's capacity to accurately capture node behavior, as evidenced by a high $R^2$ value of 0.983 for nodal flow predictions. This result indicates the model's ability to learn injection patterns at the nodes, even under nonlinear system conditions.

Incorporating the gas balance loss in subsequent experiments maintained the accuracy of nodal predictions, with no notable change in the $R^2$ for node flows. However, the slight reduction in the $R^2$ for edge flows to 0.973 suggests that while the gas balance constraint improved overall network consistency, it introduced additional complexity that slightly affected edge prediction performance. This outcome highlights a trade-off between accurate node predictions and balanced edge flows, indicating robust model performance with some sensitivity to changes in loss function configurations.

Further exploration of the model's response to including the Weymouth equation loss introduced more pronounced effects, particularly on edge flow predictions. The decline in $R^2$ to 0.952 for edge flows indicates increased difficulty in accurately modeling flow through specific network paths, particularly in regions with closed loops or compressor installations. This outcome underscores the challenge of incorporating multiple nonlinear physical constraints, especially in complex configurations.

In the experiment where only the Weymouth equation and node losses were considered, the model maintained a high $R^2$ for nodal flows. However, the extremely low $R^2$ for edge predictions, reaching negative values, suggests the model struggled to generalize edge flows effectively when isolated from balancing and edge losses. This finding reinforces the need for a comprehensive loss framework incorporating node and edge dynamics to ensure robust network performance, highlighting the challenges of predicting edge flows under limited constraints.

Comparing the results from \cref{cap:lienal-censnet} with those in \cref{cap:non_linealcensnet} reveals that the addition of physical constraints in \cref{cap:non_linealcensnet} improves model performance, particularly in terms of balancing accuracy.

The losses presented in \cref{cap:lienal-censnet} (Table \ref{tab:lineal_dummy_results}) reflect initial configurations with only nodal and edge losses. In these setups, while nodal and edge values show reasonable consistency with the APOPT optimizer, the balance values exhibit higher variability, especially in the GNN configurations. For example, when both nodal and edge losses are applied, the GNN model in \cref{cap:lienal-censnet} produces a balance error of \(-5.711 \pm 16.854\), which differs significantly from the APOPT optimizer's near-zero balance error (\(-0.001 \pm 0.038\)). This difference indicates that the simpler GNN models in \cref{cap:lienal-censnet} lack additional constraints to replicate the physical conditions accurately.

In \cref{cap:non_linealcensnet}, adding constraints related to balance and the Weymouth equation (Table \ref{tab:base_nl_dummy_results_formatted}) leads to improved balance accuracy. For instance, the GNN model with nodal, edge, and balance losses achieves a balance error of \(0.004 \pm 0.845\), considerably lower and more consistent with the IPOPT optimizer. This improvement demonstrates how adding balance constraints reduces variability and error associated with balance. Additionally, GNN configurations that include balance and Weymouth constraints (i.e., N, E, B, W) sustain this balance improvement while closely aligning with APOPT, which results in nodal and edge values.

% Overall, the experiments in \cref{cap:non_linealcensnet} show that by introducing these physical constraints, the GNN model achieves lower balance errors and maintains high-quality responses across all evaluated metrics. This finding confirms that incorporating additional constraints in the model configuration leads to more accurate and physically consistent results, bringing model performance closer to optimizer methods.



In the second experiment, the performance of the GNN-based model was evaluated in three configurations with different combinations of loss functions applied to the Colombian natural gas network. For each configuration, it was possible to consider the nodal losses, the losses associated with the edges, and the gas balance dede. The analysis provides information on the trade-offs and improvements observed with each additional loss function.

The first configuration of the GNN model, which incorporated nodal and edge losses, achieved high accuracy in predicting nodal flows with an $R^2$ score of $0.993$ while maintaining an edge prediction $R^2$ of $0.963$. This configuration showed strong performance in nodal predictions,  suggesting that focusing on this loss combination allows a good approximation of nodal flows in the system. The balance loss value, calculated independently, highlighted minimal deviation, indicating that nodal accuracy alone could achieve network consistency for this setup. These results underscore the model's capacity to generalize nodal flow predictions while capturing nodal behaviors, making this configuration efficient for applications where nodal flow prediction is prioritized.

The second configuration evaluated the impact of including nodal and balance losses in the model's cost function. The results demonstrated a stable nodal prediction performance, with an $R^2$ score consistent at $0.993$, while edge predictions dropped to an $R^2$ of $0.569$. This reduction in edge prediction accuracy suggests that excluding edge loss from the cost function introduced inconsistencies in the edge flows, as reflected in the decreased $R^2$ value. Despite the moderate accuracy in edge flow predictions, the balance loss value remained relatively low, indicating stable nodal balance but highlighting a trade-off when optimizing only nodal and balance aspects. 

% This configuration suggests that while balance loss contributes to network consistency, it may only sufficiently capture edge flow dynamics with edge-specific optimization.

In the third configuration, the GNN model included all three loss types: nodal, edge, and balance. This approach achieved a slightly lower $R^2$ of $0.984$ for nodal predictions but improved the edge prediction accuracy, yielding an $R^2$ of $0.961$. The overall alignment of predictions observed in the scatterplots suggests that incorporating all three loss functions enabled the model to more comprehensively capture the patterns of both nodal and edge flows. This approach demonstrated the most balanced trade-off between nodal and edge prediction accuracy, supporting the hypothesis that optimizing all three aspects simultaneously enhances the model's capacity to predict flows in the Colombian natural gas network. 


% These findings provide valuable insights into the effects of different loss function combinations on the predictive accuracy and computational efficiency of GNN models for natural gas networks. The results highlight the balance between optimizing nodal, edge, and balance losses to meet specific predictive requirements in network modeling.

Finally, the performance of the GNN-based model for the Colombian natural gas network is compared in two experimental configurations: Chapter 2 and Chapter 4. Each experiment considered nodal, edge, and balance loss combinations, assessing their effects on prediction accuracy and computational efficiency. Notably, due to high computational demands, the experiments in Chapter 4 did not include the Weymouth equation loss.

In Chapter 2 (Table \ref{tab:lineal_col_results}), the GNN-based model, when only the nodal loss was applied, achieved a Node Value of \(11.38 \pm 49.13\) and an Edge Value of \(0.91 \pm 1.26\), with a Balance Value of \(-2.19 \pm 58.56\). The model showed relatively high accuracy in nodal predictions and achieved minimal edge prediction errors, highlighting the model’s effectiveness in capturing nodal flows without explicitly optimizing for edge loss.

In Chapter 4 (Table \ref{tab:base_nl_dummy_results_formatted}), the experiments showed varied performance depending on the losses included:

1. In the configuration considering only nodal loss, the GNN achieved a Node Value of \(11.22 \pm 49.03\) and an Edge Value of \(62.73 \pm 81.99\), with a Balance Value of \(-2.28 \pm 25.48\). Compared to Chapter 2, this configuration demonstrated a higher edge error, suggesting that solely optimizing nodal loss did not generalize as effectively for edge predictions as observed previously.

2. When both nodal and edge losses were included, the GNN model’s Node Value increased to \(12.47 \pm 48.89\), with a significant rise in Edge Value error to \(88.32 \pm 73.55\). The Balance Value was reduced to \(-1.03 \pm 1.90\), indicating improved nodal balance but an unfavorable impact on edge prediction. This result diverges from Chapter 2, where the inclusion of edge loss contributed to more consistent results in both nodal and edge values.

3. In the configuration considering nodal, edge, and balance losses, the GNN model achieved a Node Value of \(12.33 \pm 48.64\), with an Edge Value of \(63.06 \pm 81.32\) and a Balance Value of \(-1.17 \pm 7.38\). This approach achieved better balance accuracy but did not markedly improve edge error over configurations excluding balance loss, contrasting with Chapter 2, where combined losses had more favorable outcomes.

Across both chapters, it is clear that optimizing for multiple loss functions introduces complexity, with varied impacts on nodal and edge prediction accuracy. The Chapter 4 results indicate that including balance and edge losses improves nodal balance but can lead to edge-accuracy trade-offs. Further optimization strategies or alternative methods may be required to balance all metrics.


The stochastic analysis performed on the 8-node network provided valuable insights into the inherent uncertainty of the system. By fitting a kernel density estimate (KDE) to the training input data and generating synthetic input samples (\(X_{\text{sample}}\)), these were propagated through the trained network to obtain corresponding outputs (\(y_{\text{sample}}\)). A second KDE was then fitted to the training outputs (\(y_{\text{train}}\)), and log-likelihood values were computed for both \(y_{\text{sample}}\) and the outputs derived from the training inputs (\(\bar{y}_{\text{train}}\)). The proximity of these log-likelihood values, along with high p-values and low test statistics from the Kolmogorov–Smirnov tests, confirms that the synthetic outputs closely mirror the original training output distribution. This result validates the stochastic sampling approach and indicates that the model accurately captures the underlying data distribution, enabling rapid evaluation of new scenarios.

A similar stochastic analysis was conducted on the Colombian natural gas network. In this case, the log-likelihood computed from the synthetic outputs was \(-104,413,419.34\) compared to \(-104,037,047.58\) for the training outputs. The Kolmogorov–Smirnov tests, performed under various alternatives, yielded low test statistics and high p-values, further supporting the similarity between the two distributions. These outcomes underscore the robustness of the stochastic framework, demonstrating that the trained model generalizes well to new, unseen scenarios. Consequently, the approach enhances the understanding of model uncertainties and provides a reliable basis for rapid scenario analysis and uncertainty quantification of natural gas network operations.


